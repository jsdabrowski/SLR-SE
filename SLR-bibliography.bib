% Encoding: UTF-8

@InProceedings{DBLP:conf/icsoft/ShahSP18a,
  author        = {Faiz Ali Shah and Kairit Sirts and Dietmar Pfahl},
  title         = {Simplifying the Classification of App Reviews Using Only Lexical Features},
  booktitle     = {Software Technologies - 13th International Conference, {ICSOFT} 2018, Porto, Portugal, July 26-28, 2018, Revised Selected Papers},
  year          = {2018},
  pages         = {173--193},
  __markedentry = {[jacekdabrowski:2]},
  bibsource     = {dblp computer science bibliography, https://dblp.org},
  biburl        = {https://dblp.org/rec/bib/conf/icsoft/ShahSP18a},
  crossref      = {DBLP:conf/icsoft/2018s},
  timestamp     = {Fri, 27 Dec 2019 21:26:38 +0100},
}

@InProceedings{DBLP:conf/refsq/DalpiazP19,
  author        = {Fabiano Dalpiaz and Micaela Parente},
  title         = {{RE-SWOT:} From User Feedback to Requirements via Competitor Analysis},
  booktitle     = {Requirements Engineering: Foundation for Software Quality - 25th International Working Conference, {REFSQ} 2019, Essen, Germany, March 18-21, 2019, Proceedings},
  year          = {2019},
  pages         = {55--70},
  __markedentry = {[jacekdabrowski:2]},
  bibsource     = {dblp computer science bibliography, https://dblp.org},
  biburl        = {https://dblp.org/rec/bib/conf/refsq/DalpiazP19},
  crossref      = {DBLP:conf/refsq/2019},
  timestamp     = {Tue, 14 May 2019 10:00:39 +0200},
}

@InProceedings{DBLP:conf/refsq/JhaM17,
  author        = {Nishant Jha and Anas Mahmoud},
  title         = {Mining User Requirements from Application Store Reviews Using Frame Semantics},
  booktitle     = {Requirements Engineering: Foundation for Software Quality - 23rd International Working Conference, {REFSQ} 2017, Essen, Germany, February 27 - March 2, 2017, Proceedings},
  year          = {2017},
  pages         = {273--287},
  __markedentry = {[jacekdabrowski:2]},
  bibsource     = {dblp computer science bibliography, https://dblp.org},
  biburl        = {https://dblp.org/rec/bib/conf/refsq/JhaM17},
  crossref      = {DBLP:conf/refsq/2017},
  timestamp     = {Tue, 14 May 2019 10:00:39 +0200},
}

@InProceedings{DBLP:conf/refsq/ShahSP19,
  author        = {Faiz Ali Shah and Kairit Sirts and Dietmar Pfahl},
  title         = {Is the {SAFE} Approach Too Simple for App Feature Extraction? {A} Replication Study},
  booktitle     = {Requirements Engineering: Foundation for Software Quality - 25th International Working Conference, {REFSQ} 2019, Essen, Germany, March 18-21, 2019, Proceedings},
  year          = {2019},
  pages         = {21--36},
  __markedentry = {[jacekdabrowski:2]},
  bibsource     = {dblp computer science bibliography, https://dblp.org},
  biburl        = {https://dblp.org/rec/bib/conf/refsq/ShahSP19},
  crossref      = {DBLP:conf/refsq/2019},
  timestamp     = {Fri, 27 Dec 2019 21:27:34 +0100},
}

@InProceedings{DBLP:conf/refsq/0001LPS19,
  author        = {Jacek Dąbrowski and Emmanuel Letier and Anna Perini and Angelo Susi},
  title         = {Finding and Analyzing App Reviews Related to Specific Features: {A} Research Preview},
  booktitle     = {Requirements Engineering: Foundation for Software Quality - 25th International Working Conference, {REFSQ} 2019, Essen, Germany, March 18-21, 2019, Proceedings},
  year          = {2019},
  pages         = {183--189},
  __markedentry = {[jacekdabrowski:2]},
  bibsource     = {dblp computer science bibliography, https://dblp.org},
  biburl        = {https://dblp.org/rec/bib/conf/refsq/0001LPS19},
  crossref      = {DBLP:conf/refsq/2019},
  timestamp     = {Tue, 14 May 2019 10:00:39 +0200},
}

@InProceedings{DBLP:conf/refsq/LiZW18,
  author        = {Tong Li and Fan Zhang and Dan Wang},
  title         = {Automatic User Preferences Elicitation: {A} Data-Driven Approach},
  booktitle     = {Requirements Engineering: Foundation for Software Quality - 24th International Working Conference, {REFSQ} 2018, Utrecht, The Netherlands, March 19-22, 2018, Proceedings},
  year          = {2018},
  pages         = {324--331},
  __markedentry = {[jacekdabrowski:2]},
  bibsource     = {dblp computer science bibliography, https://dblp.org},
  biburl        = {https://dblp.org/rec/bib/conf/refsq/LiZW18},
  crossref      = {DBLP:conf/refsq/2018},
  timestamp     = {Tue, 14 May 2019 10:00:39 +0200},
}

@InProceedings{DBLP:conf/icsoc/WangWXS17,
  author        = {Shance Wang and Zhongjie Wang and Xiaofei Xu and Quan Z. Sheng},
  title         = {App Update Patterns: How Developers Act on User Reviews in Mobile App Stores},
  booktitle     = {Service-Oriented Computing - 15th International Conference, {ICSOC} 2017, Malaga, Spain, November 13-16, 2017, Proceedings},
  year          = {2017},
  pages         = {125--141},
  __markedentry = {[jacekdabrowski:2]},
  bibsource     = {dblp computer science bibliography, https://dblp.org},
  biburl        = {https://dblp.org/rec/bib/conf/icsoc/WangWXS17},
  crossref      = {DBLP:conf/icsoc/2017},
  timestamp     = {Tue, 14 May 2019 10:00:36 +0200},
}

@InProceedings{DBLP:conf/kbse/VuPNN15,
  author        = {Phong Minh Vu and Hung Viet Pham and Tam The Nguyen and Tung Thanh Nguyen},
  title         = {Tool Support for Analyzing Mobile App Reviews},
  booktitle     = {30th {IEEE/ACM} International Conference on Automated Software Engineering, {ASE} 2015, Lincoln, NE, USA, November 9-13, 2015},
  year          = {2015},
  pages         = {789--794},
  __markedentry = {[jacekdabrowski:2]},
  bibsource     = {dblp computer science bibliography, https://dblp.org},
  biburl        = {https://dblp.org/rec/bib/conf/kbse/VuPNN15},
  crossref      = {DBLP:conf/kbse/2015},
  timestamp     = {Wed, 16 Oct 2019 14:14:55 +0200},
}

@InProceedings{DBLP:conf/sigsoft/KhalidNSH14,
  author        = {Hammad Khalid and Meiyappan Nagappan and Emad Shihab and Ahmed E. Hassan},
  title         = {Prioritizing the devices to test your app on: a case study of Android game apps},
  booktitle     = {Proceedings of the 22nd {ACM} {SIGSOFT} International Symposium on Foundations of Software Engineering, (FSE-22), Hong Kong, China, November 16 - 22, 2014},
  year          = {2014},
  pages         = {610--620},
  __markedentry = {[jacekdabrowski:2]},
  bibsource     = {dblp computer science bibliography, https://dblp.org},
  biburl        = {https://dblp.org/rec/bib/conf/sigsoft/KhalidNSH14},
  crossref      = {DBLP:conf/sigsoft/2014},
  timestamp     = {Tue, 06 Nov 2018 16:59:23 +0100},
}

@InProceedings{DBLP:conf/kbse/VuPNN16,
  author        = {Phong Minh Vu and Hung Viet Pham and Tam The Nguyen and Tung Thanh Nguyen},
  title         = {Phrase-based extraction of user opinions in mobile app reviews},
  booktitle     = {Proceedings of the 31st {IEEE/ACM} International Conference on Automated Software Engineering, {ASE} 2016, Singapore, September 3-7, 2016},
  year          = {2016},
  pages         = {726--731},
  __markedentry = {[jacekdabrowski:2]},
  bibsource     = {dblp computer science bibliography, https://dblp.org},
  biburl        = {https://dblp.org/rec/bib/conf/kbse/VuPNN16},
  crossref      = {DBLP:conf/kbse/2016},
  timestamp     = {Wed, 16 Oct 2019 14:14:55 +0200},
}

@InProceedings{DBLP:conf/kbse/GuK15,
  author        = {Xiaodong Gu and Sunghun Kim},
  title         = {"What Parts of Your Apps are Loved by Users?" {(T)}},
  booktitle     = {30th {IEEE/ACM} International Conference on Automated Software Engineering, {ASE} 2015, Lincoln, NE, USA, November 9-13, 2015},
  year          = {2015},
  pages         = {760--770},
  __markedentry = {[jacekdabrowski:2]},
  bibsource     = {dblp computer science bibliography, https://dblp.org},
  biburl        = {https://dblp.org/rec/bib/conf/kbse/GuK15},
  crossref      = {DBLP:conf/kbse/2015},
  timestamp     = {Wed, 16 Oct 2019 14:14:55 +0200},
}

@InProceedings{DBLP:conf/refsq/JhaM17a,
  author        = {Nishant Jha and Anas Mahmoud},
  title         = {{MARC:} {A} Mobile Application Review Classifier},
  booktitle     = {Joint Proceedings of {REFSQ-2017} Workshops, Doctoral Symposium, Research Method Track, and Poster Track co-located with the 22nd International Conference on Requirements Engineering: Foundation for Software Quality {(REFSQ} 2017), Essen, Germany, February 27, 2017},
  year          = {2017},
  __markedentry = {[jacekdabrowski:2]},
  bibsource     = {dblp computer science bibliography, https://dblp.org},
  biburl        = {https://dblp.org/rec/bib/conf/refsq/JhaM17a},
  crossref      = {DBLP:conf/refsq/2017w},
  timestamp     = {Tue, 28 May 2019 16:23:43 +0200},
}

@InProceedings{DBLP:conf/seke/YangL15,
  author        = {Hui Yang and Peng Liang},
  title         = {Identification and Classification of Requirements from App User Reviews},
  booktitle     = {The 27th International Conference on Software Engineering and Knowledge Engineering, {SEKE} 2015, Wyndham Pittsburgh University Center, Pittsburgh, PA, USA, July 6-8, 2015},
  year          = {2015},
  pages         = {7--12},
  __markedentry = {[jacekdabrowski:2]},
  bibsource     = {dblp computer science bibliography, https://dblp.org},
  biburl        = {https://dblp.org/rec/bib/conf/seke/YangL15},
  crossref      = {DBLP:conf/seke/2015},
  timestamp     = {Tue, 09 Oct 2018 17:39:08 +0200},
}

@InProceedings{DBLP:conf/nldb/SangerLK17,
  author        = {Mario S{\"{a}}nger and Ulf Leser and Roman Klinger},
  title         = {Fine-Grained Opinion Mining from Mobile App Reviews with Word Embedding Features},
  booktitle     = {Natural Language Processing and Information Systems - 22nd International Conference on Applications of Natural Language to Information Systems, {NLDB} 2017, Li{\`{e}}ge, Belgium, June 21-23, 2017, Proceedings},
  year          = {2017},
  pages         = {3--14},
  __markedentry = {[jacekdabrowski:2]},
  bibsource     = {dblp computer science bibliography, https://dblp.org},
  biburl        = {https://dblp.org/rec/bib/conf/nldb/SangerLK17},
  crossref      = {DBLP:conf/nldb/2017},
  timestamp     = {Tue, 14 May 2019 10:00:53 +0200},
}

@InProceedings{DBLP:conf/sigsoft/NicolaiPPB19,
  author        = {Mariaclaudia Nicolai and Luca Pascarella and Fabio Palomba and Alberto Bacchelli},
  title         = {Healthcare Android apps: a tale of the customers' perspective},
  booktitle     = {Proceedings of the 3rd {ACM} {SIGSOFT} International Workshop on App Market Analytics, WAMA@ESEC/SIGSOFT {FSE} 2019, Tallinn, Estonia, August 27, 2019},
  year          = {2019},
  pages         = {33--39},
  __markedentry = {[jacekdabrowski:2]},
  bibsource     = {dblp computer science bibliography, https://dblp.org},
  biburl        = {https://dblp.org/rec/bib/conf/sigsoft/NicolaiPPB19},
  crossref      = {DBLP:conf/sigsoft/2019wama},
  timestamp     = {Tue, 27 Aug 2019 14:51:27 +0200},
}

@InProceedings{DBLP:conf/colcom/PengWHT16,
  author        = {Zhenlian Peng and Jian Wang and Keqing He and Mingdong Tang},
  title         = {An Approach of Extracting Feature Requests from App Reviews},
  booktitle     = {Collaborate Computing: Networking, Applications and Worksharing - 12th International Conference, CollaborateCom 2016, Beijing, China, November 10-11, 2016, Proceedings},
  year          = {2016},
  pages         = {312--323},
  __markedentry = {[jacekdabrowski:2]},
  bibsource     = {dblp computer science bibliography, https://dblp.org},
  biburl        = {https://dblp.org/rec/bib/conf/colcom/PengWHT16},
  crossref      = {DBLP:conf/colcom/2016},
  timestamp     = {Wed, 21 Feb 2018 00:53:31 +0100},
}

@InProceedings{DBLP:conf/mum/HuebnerFAFI18,
  author        = {Johannes Huebner and Remo Manuel Frey and Christian Ammendola and Elgar Fleisch and Alexander Ilic},
  title         = {What People Like in Mobile Finance Apps: An Analysis of User Reviews},
  booktitle     = {Proceedings of the 17th International Conference on Mobile and Ubiquitous Multimedia, {MUM} 2018, Cairo, Egypt, November 25-28, 2018},
  year          = {2018},
  pages         = {293--304},
  __markedentry = {[jacekdabrowski:2]},
  bibsource     = {dblp computer science bibliography, https://dblp.org},
  biburl        = {https://dblp.org/rec/bib/conf/mum/HuebnerFAFI18},
  crossref      = {DBLP:conf/mum/2018},
  timestamp     = {Tue, 18 Dec 2018 15:33:47 +0100},
}

@InProceedings{DBLP:conf/hicss/BaileyND19,
  author        = {Kendall Bailey and Meiyappan Nagappan and Danny Dig},
  title         = {Examining User-Developer Feedback Loops in the iOS App Store},
  booktitle     = {52nd Hawaii International Conference on System Sciences, {HICSS} 2019, Grand Wailea, Maui, Hawaii, USA, January 8-11, 2019},
  year          = {2019},
  pages         = {1--10},
  __markedentry = {[jacekdabrowski:2]},
  bibsource     = {dblp computer science bibliography, https://dblp.org},
  biburl        = {https://dblp.org/rec/bib/conf/hicss/BaileyND19},
  crossref      = {DBLP:conf/hicss/2019},
  timestamp     = {Wed, 10 Apr 2019 08:36:41 +0200},
}

@InProceedings{10.1145/3236024.3236044,
  author        = {Noei, Ehsan and Da Costa, Daniel Alencar and Zou, Ying},
  title         = {Winning the App Production Rally},
  booktitle     = {Proceedings of the 2018 26th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
  year          = {2018},
  series        = {ESEC/FSE 2018},
  pages         = {283–294},
  address       = {New York, NY, USA},
  publisher     = {},
  __markedentry = {[jacekdabrowski:2]},
  isbn          = {9781450355735},
  keywords      = {Mobile application, Application market, Rank, Empirical study},
  location      = {Lake Buena Vista, FL, USA},
  numpages      = {12},
}

@InProceedings{10.1145/2487575.2488202,
  author        = {Fu, Bin and Lin, Jialiu and Li, Lei and Faloutsos, Christos and Hong, Jason and Sadeh, Norman},
  title         = {Why People Hate Your App: Making Sense of User Feedback in a Mobile App Store},
  booktitle     = {Proceedings of the 19th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
  year          = {2013},
  series        = {KDD ’13},
  pages         = {1276–1284},
  address       = {New York, NY, USA},
  publisher     = {ACM},
  __markedentry = {[jacekdabrowski:2]},
  isbn          = {9781450321747},
  keywords      = {topic model, user rating and comments, sentiment analysis, text mining, mobile app market},
  location      = {Chicago, Illinois, USA},
  numpages      = {9},
}

@InProceedings{10.1145/3299815.3314473,
  author        = {Vu, Phong Minh and Nguyen, Tam The and Nguyen, Tung Thanh},
  title         = {Why Do App Reviews Get Responded: A Preliminary Study of the Relationship between Reviews and Responses in Mobile Apps},
  booktitle     = {Proceedings of the 2019 ACM Southeast Conference},
  year          = {2019},
  series        = {ACM SE ’19},
  pages         = {237–240},
  address       = {New York, NY, USA},
  publisher     = {ACM},
  __markedentry = {[jacekdabrowski:2]},
  isbn          = {9781450362511},
  keywords      = {Empirical, Review, Mobile App, Response},
  location      = {Kennesaw, GA, USA},
  numpages      = {4},
}

@InProceedings{10.1145/2950290.2950299,
  author        = {Di Sorbo, Andrea and Panichella, Sebastiano and Alexandru, Carol V. and Shimagaki, Junji and Visaggio, Corrado A. and Canfora, Gerardo and Gall, Harald C.},
  title         = {What Would Users Change in My App? Summarizing App Reviews for Recommending Software Changes},
  booktitle     = {Proceedings of the 2016 24th ACM SIGSOFT International Symposium on Foundations of Software Engineering},
  year          = {2016},
  series        = {FSE 2016},
  pages         = {499–510},
  address       = {New York, NY, USA},
  publisher     = {ACM},
  __markedentry = {[jacekdabrowski:2]},
  isbn          = {9781450342186},
  keywords      = {Mobile Application, User Feedback, Text Summarization},
  location      = {Seattle, WA, USA},
  numpages      = {12},
}

@Article{6762802,
  author        = {H. {Khalid} and E. {Shihab} and M. {Nagappan} and A. E. {Hassan}},
  title         = {What Do Mobile App Users Complain About?},
  journal       = {IEEE Software},
  year          = {2015},
  volume        = {32},
  number        = {3},
  pages         = {70-77},
  month         = {May},
  __markedentry = {[jacekdabrowski:2]},
  abstract      = {Mobile-app quality is becoming an increasingly important issue. These apps are generally delivered through app stores that let users post reviews. These reviews provide a rich data source you can leverage to understand user-reported issues. Researchers qualitatively studied 6,390 low-rated user reviews for 20 free-to-download iOS apps. They uncovered 12 types of user complaints. The most frequent complaints were functional errors, feature requests, and app crashes. Complaints about privacy and ethical issues and hidden app costs most negatively affected ratings. In 11 percent of the reviews, users attributed their complaints to a recent app update. This study provides insight into the user-reported issues of iOS apps, along with their frequency and impact, which can help developers better prioritize their limited quality assurance resources.},
  issn          = {1937-4194},
  keywords      = {mobile computing;operating systems (computers);mobile App users;mobile app quality;app stores;iOS apps;user complaints;frequent complaints;functional errors;feature requests;app crashes;ethical issues;privacy issues;quality assurance resources;Computer crashes;Privacy;Mobile communication;Tagging;Computer applications;Software quality;Quality assurance;Software engineering;mobile applications;software quality;user reviews;quality assurance;software engineering},
}

@Article{DBLP:journals/ese/JhaM18,
  author        = {Nishant Jha and Anas Mahmoud},
  title         = {Using frame semantics for classifying and summarizing application store reviews},
  journal       = {Empirical Software Engineering},
  year          = {2018},
  volume        = {23},
  number        = {6},
  pages         = {3734--3767},
  __markedentry = {[jacekdabrowski:2]},
  bibsource     = {dblp computer science bibliography, https://dblp.org},
  biburl        = {https://dblp.org/rec/bib/journals/ese/JhaM18},
  timestamp     = {Wed, 26 Dec 2018 19:52:06 +0100},
}

@InProceedings{10.1145/3340496.3342756,
  author        = {Shah, Faiz Ali and Sirts, Kairit and Pfahl, Dietmar},
  title         = {Using App Reviews for Competitive Analysis: Tool Support},
  booktitle     = {Proceedings of the 3rd ACM SIGSOFT International Workshop on App Market Analytics},
  year          = {2019},
  series        = {WAMA 2019},
  pages         = {40–46},
  address       = {New York, NY, USA},
  publisher     = {ACM},
  __markedentry = {[jacekdabrowski:2]},
  isbn          = {9781450368582},
  keywords      = {app review classification, sentiment analysis, competitive analysis, app feature extraction, App review analysis},
  location      = {Tallinn, Estonia},
  numpages      = {7},
}

@InProceedings{7332475,
  author        = {F. {Palomba} and M. {Linares-Vásquez} and G. {Bavota} and R. {Oliveto} and M. {Di Penta} and D. {Poshyvanyk} and A. {De Lucia}},
  title         = {User reviews matter! Tracking crowdsourced reviews to support evolution of successful apps},
  booktitle     = {2015 IEEE International Conference on Software Maintenance and Evolution (ICSME)},
  year          = {2015},
  pages         = {291-300},
  month         = {Sep.},
  __markedentry = {[jacekdabrowski:2]},
  abstract      = {Nowadays software applications, and especially mobile apps, undergo frequent release updates through app stores. After installing/updating apps, users can post reviews and provide ratings, expressing their level of satisfaction with apps, and possibly pointing out bugs or desired features. In this paper we show-by performing a study on 100 Android apps-how developers addressing user reviews increase their app's success in terms of ratings. Specifically, we devise an approach, named CRISTAL, for tracing informative crowd reviews onto source code changes, and for monitoring the extent to which developers accommodate crowd requests and follow-up user reactions as reflected in their ratings. The results indicate that developers implementing user reviews are rewarded in terms of ratings. This poses the need for specialized recommendation systems aimed at analyzing informative crowd reviews and prioritizing feedback to be satisfied in order to increase the apps success.},
  issn          = {null},
  keywords      = {mobile computing;recommender systems;source code (software);user review;crowdsourced review tracking;mobile apps;app stores;Android apps;CRISTAL;informative crowd review tracing;source code change;crowd request;user reaction;ratings;specialized recommendation systems;Monitoring;Androids;Humanoid robots;Entropy;Planning;Joining processes;Feature extraction},
}

@InProceedings{6636712,
  author        = {D. {Pagano} and W. {Maalej}},
  title         = {User feedback in the appstore: An empirical study},
  booktitle     = {2013 21st IEEE International Requirements Engineering Conference (RE)},
  year          = {2013},
  pages         = {125-134},
  month         = {July},
  __markedentry = {[jacekdabrowski:2]},
  issn          = {2332-6441},
  keywords      = {formal verification;human factors;Internet;systems analysis;application distribution platforms;Google Play;Apple AppStore;feedback content;user community;positive messages;negative feedback;software teams;requirements engineering teams;Communities;Software;Catalogs;Social network services;Games;Google;Navigation;user needs;user feedback;mobile requirements},
}

@InProceedings{8445154,
  author        = {E. {Guzman} and L. {Oliveira} and Y. {Steiner} and L. C. {Wagner} and M. {Glinz}},
  title         = {User Feedback in the App Store: A Cross-Cultural Study},
  booktitle     = {2018 IEEE/ACM 40th International Conference on Software Engineering: Software Engineering in Society (ICSE-SEIS)},
  year          = {2018},
  pages         = {13-22},
  month         = {May},
  __markedentry = {[jacekdabrowski:2]},
  issn          = {null},
  keywords      = {cultural aspects;diverse national culture;cultural factors;automated feedback analysis tools;user feedback;user reviews;software evolution;bug reports;feature requests;cultural differences;app store reviews;cultural dimensions;Cultural differences;Software;Classification algorithms;Software engineering;Software algorithms;Indexes;Computer bugs;User Feedback;Feedback Analysis;Culture;Algorithm Bias;Software Evolution},
}

@InProceedings{8501305,
  author        = {G. {Deshpande} and J. {Rokne}},
  title         = {User Feedback from Tweets vs App Store Reviews: An Exploratory Study of Frequency, Timing and Content},
  booktitle     = {2018 5th International Workshop on Artificial Intelligence for Requirements Engineering (AIRE)},
  year          = {2018},
  pages         = {15-21},
  month         = {Aug},
  __markedentry = {[jacekdabrowski:2]},
  abstract      = {Context: User feedback on apps is essential for gauging market needs and maintaining a competitive edge in the mobile apps development industry. App Store Reviews have been a primary resource for this feedback, however, recent studies have observed that Twitter is another potentially valuable source for this information. Objective: The objective of this study is to assess user feedback from Twitter in terms of timing as well as content and compare with the App Store reviews. Method: This study employs various text analysis and Natural Language Processing methods such as semantic analysis and Latent Dirichlet Allocation (LDA) to analyze tweets and App Store Reviews. Additionally, supervised learning classifiers are used to classify them as semantically similar tweet and App Store reviews. Results: In spite of a difference in the magnitude between tweets and App Store Review counts, frequency analysis shows that bug report and feature request are discussed mostly on Twitter first as the number of Tweets during the reporting time reached the peak a few days earlier. Likewise, timing analysis on a set of 426 tweets and 2,383 reviews (which are bug reports and feature requests) show that approximately 15% appear on Twitter first. Of these 15% tweets, 72% are related to functional or behavioural aspects of the mobile app. Content analysis shows that user feedback in tweets mostly focuses on critical issues related to the feature failure and improper functionality. Conclusion: The results of this investigation show that the Twitter is not only a strong contender for useful information but also a faster source of information for mobile app improvement.},
  issn          = {null},
  keywords      = {learning (artificial intelligence);mobile computing;natural language processing;pattern classification;program debugging;reviews;social networking (online);text analysis;tweets;Twitter;user feedback;mobile apps development industry;frequency analysis;timing analysis;content analysis;gauging market;text analysis;natural language processing methods;semantic analysis;Latent Dirichlet allocation;LDA;supervised learning classifiers;magnitude;App store reviews counts;bug report;behavioural aspects;functional aspects;Twitter;Computer bugs;Google;Timing;Semantics;Market research;LinkedIn;social media, user feedback, mobile apps, machine learning, text analysis, natural language processing, mobile application improvement.},
}

@InProceedings{10.1145/3314183.3323676,
  author        = {Alqahtani, Felwah and Orji, Rita},
  title         = {Usability Issues in Mental Health Applications},
  booktitle     = {Adjunct Publication of the 27th Conference on User Modeling, Adaptation and Personalization},
  year          = {2019},
  series        = {UMAP’19 Adjunct},
  pages         = {343–348},
  address       = {New York, NY, USA},
  publisher     = {ACM},
  __markedentry = {[jacekdabrowski:2]},
  isbn          = {9781450367110},
  keywords      = {user experience, usability issues, thematic analysis, mental health apps, low engagement},
  location      = {Larnaca, Cyprus},
  numpages      = {6},
}

@Article{DBLP:journals/ese/MartensM19,
  author        = {Daniel Martens and Walid Maalej},
  title         = {Towards understanding and detecting fake reviews in app stores},
  journal       = {Empirical Software Engineering},
  year          = {2019},
  volume        = {24},
  number        = {6},
  pages         = {3316--3355},
  __markedentry = {[jacekdabrowski:2]},
  bibsource     = {dblp computer science bibliography, https://dblp.org},
  biburl        = {https://dblp.org/rec/bib/journals/ese/MartensM19},
  timestamp     = {Thu, 19 Dec 2019 09:26:48 +0100},
}

@Article{DBLP:journals/ese/NoeiZWZ19,
  author        = {Ehsan Noei and Feng Zhang and Shaohua Wang and Ying Zou},
  title         = {Towards prioritizing user-related issue reports of mobile applications},
  journal       = {Empirical Software Engineering},
  year          = {2019},
  volume        = {24},
  number        = {4},
  pages         = {1964--1996},
  __markedentry = {[jacekdabrowski:2]},
  bibsource     = {dblp computer science bibliography, https://dblp.org},
  biburl        = {https://dblp.org/rec/bib/journals/ese/NoeiZWZ19},
  timestamp     = {Wed, 20 Nov 2019 09:02:52 +0100},
}

@Article{7325177,
  author        = {W. {Maalej} and M. {Nayebi} and T. {Johann} and G. {Ruhe}},
  title         = {Toward Data-Driven Requirements Engineering},
  journal       = {IEEE Software},
  year          = {2016},
  volume        = {33},
  number        = {1},
  pages         = {48-54},
  month         = {Jan},
  __markedentry = {[jacekdabrowski:2]},
  abstract      = {Nowadays, users can easily submit feedback about software products in app stores, social media, or user groups. Moreover, software vendors are collecting massive amounts of implicit feedback in the form of usage data, error logs, and sensor data. These trends suggest a shift toward data-driven user-centered identification, prioritization, and management of software requirements. Developers should be able to adopt the requirements of masses of users when deciding what to develop and when to release. They could systematically use explicit and implicit user data in an aggregated form to support requirements decisions. The goal is data-driven requirements engineering by the masses and for the masses.},
  issn          = {1937-4194},
  keywords      = {formal specification;software management;data-driven requirements engineering;user feedback;software products;software vendors;usage data;error logs;sensor data;data-driven user-centered software requirement identification;data-driven user-centered software requirement prioritization;data-driven user-centered software requirement management;explicit user data;implicit user data;Requirements engineering;Software engineering;Stakeholders;Media;Feature extraction;Market research;app reviews;decision support;requirements engineering;software analytics;usage data;software engineering;software development},
}

@InProceedings{10.1109/SERP4IoT.2019.00013,
  author        = {Truelove, Andrew and Chowdhury, Farah Naz and Gnawali, Omprakash and Alipour, Mohammad Amin},
  title         = {Topics of Concern: Identifying User Issues in Reviews of IoT Apps and Devices},
  booktitle     = {Proceedings of the 1st International Workshop on Software Engineering Research \& Practices for the Internet of Things},
  year          = {2019},
  series        = {SERP4IoT ’19},
  pages         = {33–40},
  publisher     = {IEEE Press},
  __markedentry = {[jacekdabrowski:2]},
  location      = {Montreal, Quebec, Canada},
  numpages      = {8},
}

@Article{8613795,
  author        = {E. {Noei} and F. {Zhang} and Y. {Zou}},
  title         = {Too Many User-Reviews, What Should App Developers Look at First?},
  journal       = {IEEE Transactions on Software Engineering},
  year          = {2019},
  pages         = {1-1},
  __markedentry = {[jacekdabrowski:2]},
  abstract      = {Due to the rapid growth in the number of mobile applications (apps) in the past few years, succeeding in mobile app markets has become ruthless. Online app markets, such as Google Play Store, let users rate apps on a five-star scale and leave feedback. Given the importance of high star-ratings to the success of an app, it is crucial to help developers find the key topics of user-reviews that are significantly related to star-ratings of a given category. Having considered the key topics of user-reviews, app developers can narrow down their effort to the user-reviews that matter to be addressed for receiving higher star-ratings. We study 4,193,549 user-reviews of 623 Android apps that were collected from Google Play Store in ten different categories. The results show that few key topics commonly exist across categories, and each category has a specific set of key topics. We also evaluated the identified key topics with respect to the changes that are made to each version of the apps for 19 months. We observed, for 77% of the apps, considering the key topics in the next versions shares a significant relationship with increases in star-ratings.},
  issn          = {2326-3881},
  keywords      = {Google;Measurement;Crawlers;Natural language processing;Computer bugs;Tools;Filtering;Mobile application;Empirical study;Software release;User-review},
}

@InProceedings{10.1145/2993259.2993268,
  author        = {Mercado, Iv\'{a}n Tactuk and Munaiah, Nuthan and Meneely, Andrew},
  title         = {The Impact of Cross-Platform Development Approaches for Mobile Applications from the User’s Perspective},
  booktitle     = {Proceedings of the International Workshop on App Market Analytics},
  year          = {2016},
  series        = {WAMA 2016},
  pages         = {43–49},
  address       = {New York, NY, USA},
  publisher     = {ACM},
  __markedentry = {[jacekdabrowski:2]},
  isbn          = {9781450343985},
  keywords      = {quality, user reviews, cross-platform, mobile development},
  location      = {Seattle, WA, USA},
  numpages      = {7},
}

@InProceedings{10.5555/2820518.2820535,
  author        = {Martin, William and Harman, Mark and Jia, Yue and Sarro, Federica and Zhang, Yuanyuan},
  title         = {The App Sampling Problem for App Store Mining},
  booktitle     = {Proceedings of the 12th Working Conference on Mining Software Repositories},
  year          = {2015},
  series        = {MSR ’15},
  pages         = {123–133},
  publisher     = {IEEE Press},
  __markedentry = {[jacekdabrowski:2]},
  isbn          = {9780769555942},
  location      = {Florence, Italy},
  numpages      = {11},
}

@InProceedings{10.1109/ICSE-C.2017.5,
  author        = {Di Sorbo, Andrea and Panichella, Sebastiano and Alexandru, Carol V. and Visaggio, Corrado A. and Canfora, Gerardo},
  title         = {SURF: Summarizer of User Reviews Feedback},
  booktitle     = {Proceedings of the 39th International Conference on Software Engineering Companion},
  year          = {2017},
  series        = {ICSE-C ’17},
  pages         = {55–58},
  publisher     = {IEEE Press},
  __markedentry = {[jacekdabrowski:2]},
  isbn          = {9781538615898},
  keywords      = {mobile applications, summarization, natural language processing, software maintenance},
  location      = {Buenos Aires, Argentina},
  numpages      = {4},
}

@Article{DBLP:journals/ese/HassanTBH18,
  author        = {Safwat Hassan and Chakkrit Tantithamthavorn and Cor{-}Paul Bezemer and Ahmed E. Hassan},
  title         = {Studying the dialogue between users and developers of free apps in the Google Play Store},
  journal       = {Empirical Software Engineering},
  year          = {2018},
  volume        = {23},
  number        = {3},
  pages         = {1275--1312},
  __markedentry = {[jacekdabrowski:2]},
  bibsource     = {dblp computer science bibliography, https://dblp.org},
  biburl        = {https://dblp.org/rec/bib/journals/ese/HassanTBH18},
  timestamp     = {Wed, 25 Sep 2019 17:57:14 +0200},
}

@Article{DBLP:journals/ese/HuBH18,
  author        = {Hanyang Hu and Cor{-}Paul Bezemer and Ahmed E. Hassan},
  title         = {Studying the consistency of star ratings and the complaints in 1 {\&} 2-star user reviews for top free cross-platform Android and iOS apps},
  journal       = {Empirical Software Engineering},
  year          = {2018},
  volume        = {23},
  number        = {6},
  pages         = {3442--3475},
  __markedentry = {[jacekdabrowski:2]},
  bibsource     = {dblp computer science bibliography, https://dblp.org},
  biburl        = {https://dblp.org/rec/bib/journals/ese/HuBH18},
}

@Article{DBLP:journals/ese/HuWBH19,
  author        = {Hanyang Hu and Shaowei Wang and Cor{-}Paul Bezemer and Ahmed E. Hassan},
  title         = {Studying the consistency of star ratings and reviews of popular free hybrid Android and iOS apps},
  journal       = {Empirical Software Engineering},
  year          = {2019},
  volume        = {24},
  number        = {1},
  pages         = {7--32},
  __markedentry = {[jacekdabrowski:2]},
  bibsource     = {dblp computer science bibliography, https://dblp.org},
  biburl        = {https://dblp.org/rec/bib/journals/ese/HuWBH19},
  timestamp     = {Wed, 27 Feb 2019 18:48:53 +0100},
}

@Article{8457304,
  author        = {S. {Hassan} and C. {Bezemer} and A. E. {Hassan}},
  title         = {Studying Bad Updates of Top Free-to-Download Apps in the Google Play Store},
  journal       = {IEEE Transactions on Software Engineering},
  year          = {2018},
  pages         = {1-1},
  __markedentry = {[jacekdabrowski:2]},
  issn          = {2326-3881},
  keywords      = {Google;Computer bugs;Feature extraction;Global Positioning System;User interfaces;History;mobile app reviews;Google Play Store;bad updates;Android mobile apps},
}

@InProceedings{10.1145/3194095.3194096,
  author        = {Srisopha, Kamonphop and Alfayez, Reem},
  title         = {Software Quality through the Eyes of the End-User and Static Analysis Tools: A Study on Android OSS Applications},
  booktitle     = {Proceedings of the 1st International Workshop on Software Qualities and Their Dependencies},
  year          = {2018},
  series        = {SQUADE ’18},
  pages         = {1–4},
  address       = {New York, NY, USA},
  publisher     = {ACM},
  __markedentry = {[jacekdabrowski:2]},
  isbn          = {9781450357371},
  keywords      = {software evolution, software quality, static analysis, user satisfaction, software engineering},
  location      = {Gothenburg, Sweden},
  numpages      = {4},
}

@InProceedings{8918986,
  author        = {K. {Srisopha} and C. {Phonsom} and K. {Lin} and B. {Boehm}},
  title         = {Same App, Different Countries: A Preliminary User Reviews Study on Most Downloaded iOS Apps},
  booktitle     = {2019 IEEE International Conference on Software Maintenance and Evolution (ICSME)},
  year          = {2019},
  pages         = {76-80},
  month         = {Sep.},
  __markedentry = {[jacekdabrowski:2]},
  abstract      = {Prior work on mobile app reviews has demonstrated that user reviews contain a wealth of information and are seen as a potential source of requirements. However, most of the studies done in this area mainly focused on mining and analyzing user reviews from the US App Store, leaving reviews of users from other countries unexplored. In this paper, we seek to understand if the perception of the same apps between users from other countries and that from the US differs through analyzing user reviews. We retrieve 300,643 user reviews of the 15 most downloaded iOS apps of 2018, published directly by Apple, from nine English-speaking countries over the course of 5 months. We manually classify 3,358 reviews into several software quality and improvement factors. We leverage a random forest based algorithm to identify factors that can be used to differentiate reviews between the US and other countries. Our preliminary results show that all countries have some factors that are proportionally inconsistent with the US.},
  issn          = {1063-6773},
  keywords      = {Software quality;Google;Security;Software maintenance;Forestry;Software algorithms;User Reviews Analysis;App Store Analytics;Requirement Engineering;Text Mining;Software Evolution},
}

@InProceedings{10.1109/MOBILESoft.2017.3,
  author        = {Ali, Mohamed and Joorabchi, Mona Erfani and Mesbah, Ali},
  title         = {Same App, Different App Stores: A Comparative Study},
  booktitle     = {Proceedings of the 4th International Conference on Mobile Software Engineering and Systems},
  year          = {2017},
  series        = {MOBILESoft ’17},
  pages         = {79–90},
  publisher     = {IEEE Press},
  __markedentry = {[jacekdabrowski:2]},
  isbn          = {9781538626696},
  keywords      = {app stores, cross-platform apps, Android, iOS},
  location      = {Buenos Aires, Argentina},
  numpages      = {12},
}

@InProceedings{8048887,
  author        = {T. {Johann} and C. {Stanik} and A. M. A. {B.} and W. {Maalej}},
  title         = {SAFE: A Simple Approach for Feature Extraction from App Descriptions and App Reviews},
  booktitle     = {2017 IEEE 25th International Requirements Engineering Conference (RE)},
  year          = {2017},
  pages         = {21-30},
  month         = {Sep.},
  __markedentry = {[jacekdabrowski:2]},
  abstract      = {A main advantage of app stores is that they aggregate important information created by both developers and users. In the app store product pages, developers usually describe and maintain the features of their apps. In the app reviews, users comment these features. Recent studies focused on mining app features either as described by developers or as reviewed by users. However, extracting and matching the features from the app descriptions and the reviews is essential to bear the app store advantages, e.g. allowing analysts to identify which app features are actually being reviewed and which are not. In this paper, we propose SAFE, a novel uniform approach to extract app features from the single app pages, the single reviews and to match them. We manually build 18 part-of-speech patterns and 5 sentence patterns that are frequently used in text referring to app features. We then apply these patterns with several text pre-and post-processing steps. A major advantage of our approach is that it does not require large training and configuration data. To evaluate its accuracy, we manually extracted the features mentioned in the pages and reviews of 10 apps. The extraction precision and recall outperformed two state-of-the-art approaches. For well-maintained app pages such as for Google Drive our approach has a precision of 87% and on average 56% for 10 evaluated apps. SAFE also matches 87% of the features extracted from user reviews to those extracted from the app descriptions.},
  issn          = {2332-6441},
  keywords      = {data mining;feature extraction;mobile computing;text analysis;user interfaces;SAFE;user reviews;app descriptions;feature extraction;app reviews;app stores;app feature mining;part-of-speech patterns;Google Drive;Feature extraction;Software;Tools;Games;Videos;Business;Requirements engineering;User Reviews;App Store Analytics;Software Feature;Data Mining;Data-Driven Requirements},
}

@InProceedings{7321214,
  author        = {E. {Guzman} and O. {Aly} and B. {Bruegge}},
  title         = {Retrieving Diverse Opinions from App Reviews},
  booktitle     = {2015 ACM/IEEE International Symposium on Empirical Software Engineering and Measurement (ESEM)},
  year          = {2015},
  pages         = {1-10},
  month         = {Oct},
  __markedentry = {[jacekdabrowski:2]},
  issn          = {1949-3789},
  keywords      = {information retrieval;software engineering;App reviews;software development;sentiment centric retrieval approach;diverse opinion retrieval;software evolution;Feature extraction;Software;Sentiment analysis;Greedy algorithms;Google;Measurement;Information retrieval},
}

@InProceedings{7886888,
  author        = {L. {Villarroel} and G. {Bavota} and B. {Russo} and R. {Oliveto} and M. {Di Penta}},
  title         = {Release Planning of Mobile Apps Based on User Reviews},
  booktitle     = {2016 IEEE/ACM 38th International Conference on Software Engineering (ICSE)},
  year          = {2016},
  pages         = {14-24},
  month         = {May},
  __markedentry = {[jacekdabrowski:2]},
  abstract      = {Developers have to to constantly improve their apps by fixing critical bugs and implementing the most desired features in order to gain shares in the continuously increasing and competitive market of mobile apps. A precious source of information to plan such activities is represented by reviews left by users on the app store. However, in order to exploit such information developers need to manually analyze such reviews. This is something not doable if, as frequently happens, the app receives hundreds of reviews per day. In this paper we introduce CLAP (Crowd Listener for releAse Planning), a thorough solution to (i) categorize user reviews based on the information they carry out (e.g., bug reporting), (ii) cluster together related reviews (e.g., all reviews reporting the same bug), and (iii) automatically prioritize the clusters of reviews to be implemented when planning the subsequent app release. We evaluated all the steps behind CLAP, showing its high accuracy in categorizing and clustering reviews and the meaningfulness of the recommended prioritizations. Also, given the availability of CLAP as a working tool, we assessed its practical applicability in industrial environments.},
  issn          = {1558-1225},
  keywords      = {mobile computing;software maintenance;release planning;mobile applications;user review;app store;information source;CLAP;crowd listener for release planning;Computer bugs;Mobile communication;Planning;Thesauri;Software;Machine learning algorithms;Merging},
}

@InProceedings{10.1109/ICSE.2017.18,
  author        = {Palomba, Fabio and Salza, Pasquale and Ciurumelea, Adelina and Panichella, Sebastiano and Gall, Harald and Ferrucci, Filomena and De Lucia, Andrea},
  title         = {Recommending and Localizing Change Requests for Mobile Apps Based on User Reviews},
  booktitle     = {Proceedings of the 39th International Conference on Software Engineering},
  year          = {2017},
  series        = {ICSE ’17},
  pages         = {106–117},
  publisher     = {IEEE Press},
  __markedentry = {[jacekdabrowski:2]},
  isbn          = {9781538638682},
  keywords      = {natural language processing, mining user reviews, mobile apps, impact analysis},
  location      = {Buenos Aires, Argentina},
  numpages      = {12},
}

@InProceedings{10.1145/3084226.3084285,
  author        = {Deocadez, Roger and Harrison, Rachel and Rodriguez, Daniel},
  title         = {Preliminary Study on Applying Semi-Supervised Learning to App Store Analysis},
  booktitle     = {Proceedings of the 21st International Conference on Evaluation and Assessment in Software Engineering},
  year          = {2017},
  series        = {EASE’17},
  pages         = {320–323},
  address       = {New York, NY, USA},
  publisher     = {ACM},
  __markedentry = {[jacekdabrowski:2]},
  isbn          = {9781450348041},
  keywords      = {Semi-supervised Learning, Apps reviews, Mobile apps},
  location      = {Karlskrona, Sweden},
  numpages      = {4},
}

@InProceedings{10.1145/3266237.3266272,
  author        = {Durelli, Vinicius H. S. and Durelli, Rafael S. and Endo, Andre T. and Cirilo, Elder and Luiz, Washington and Rocha, Leonardo},
  title         = {Please Please Me: Does the Presence of Test Cases Influence Mobile App Users’ Satisfaction?},
  booktitle     = {Proceedings of the XXXII Brazilian Symposium on Software Engineering},
  year          = {2018},
  series        = {SBES ’18},
  pages         = {132–141},
  address       = {New York, NY, USA},
  publisher     = {ACM},
  __markedentry = {[jacekdabrowski:2]},
  isbn          = {9781450365031},
  keywords      = {software testing, mobile application, sentiment analysis},
  location      = {Sao Carlos, Brazil},
  numpages      = {10},
}

@InProceedings{10.1145/3180155.3180218,
  author        = {Gao, Cuiyun and Zeng, Jichuan and Lyu, Michael R. and King, Irwin},
  title         = {Online App Review Analysis for Identifying Emerging Issues},
  booktitle     = {Proceedings of the 40th International Conference on Software Engineering},
  year          = {2018},
  series        = {ICSE ’18},
  pages         = {48–58},
  address       = {New York, NY, USA},
  publisher     = {ACM},
  __markedentry = {[jacekdabrowski:2]},
  isbn          = {9781450356381},
  keywords      = {app reviews, emerging issues, online analysis},
  location      = {Gothenburg, Sweden},
  numpages      = {11},
}

@Article{DBLP:journals/re/KurtanovicM18,
  author        = {Zijad Kurtanovic and Walid Maalej},
  title         = {On user rationale in software engineering},
  journal       = {Requir. Eng.},
  year          = {2018},
  volume        = {23},
  number        = {3},
  pages         = {357--379},
  __markedentry = {[jacekdabrowski:2]},
  bibsource     = {dblp computer science bibliography, https://dblp.org},
  biburl        = {https://dblp.org/rec/bib/journals/re/KurtanovicM18},
  timestamp     = {Thu, 13 Sep 2018 18:11:47 +0200},
}

@InProceedings{10.5555/3105556.3105559,
  author        = {Martens, Daniel and Johann, Timo},
  title         = {On the Emotion of Users in App Reviews},
  booktitle     = {Proceedings of the 2nd International Workshop on Emotion Awareness in Software Engineering},
  year          = {2017},
  series        = {SEmotion ’17},
  pages         = {8–14},
  publisher     = {IEEE Press},
  __markedentry = {[jacekdabrowski:2]},
  isbn          = {9781538627938},
  location      = {Buenos Aires, Argentina},
  numpages      = {7},
}

@Article{DBLP:journals/re/MaalejKNS16,
  author        = {Walid Maalej and Zijad Kurtanovic and Hadeer Nabil and Christoph Stanik},
  title         = {On the automatic classification of app reviews},
  journal       = {Requir. Eng.},
  year          = {2016},
  volume        = {21},
  number        = {3},
  pages         = {311--331},
  __markedentry = {[jacekdabrowski:2]},
  bibsource     = {dblp computer science bibliography, https://dblp.org},
  biburl        = {https://dblp.org/rec/bib/journals/re/MaalejKNS16},
  timestamp     = {Sat, 20 May 2017 00:26:07 +0200},
}

@InProceedings{10.1145/3106237.3106294,
  author        = {Wei, Lili and Liu, Yepang and Cheung, Shing-Chi},
  title         = {OASIS: Prioritizing Static Analysis Warnings for Android Apps Based on App User Reviews},
  booktitle     = {Proceedings of the 2017 11th Joint Meeting on Foundations of Software Engineering},
  year          = {2017},
  series        = {ESEC/FSE 2017},
  pages         = {672–682},
  address       = {New York, NY, USA},
  publisher     = {ACM},
  __markedentry = {[jacekdabrowski:2]},
  isbn          = {9781450351058},
  keywords      = {Static analysis, natural language processing, Android Lint, concept graph, app user reviews, warning prioritization},
  location      = {Paderborn, Germany},
  numpages      = {11},
}

@InCollection{NAGAPPAN201647,
  author        = {M. Nagappan and E. Shihab},
  title         = {Mobile app store analytics},
  booktitle     = {Perspectives on Data Science for Software Engineering},
  publisher     = {Morgan Kaufmann},
  year          = {2016},
  editor        = {Tim Menzies and Laurie Williams and Thomas Zimmermann},
  pages         = {47 - 49},
  address       = {Boston},
  __markedentry = {[jacekdabrowski:2]},
  abstract      = {Today, software engineering research focuses on traditional software systems like the Firefox web browser or Microsoft Windows, which take years to develop by teams of designers, developers, and debuggers. Software engineering is rapidly changing, though. Emerging domains, such as mobile devices, are growing rapidly and depend heavily on new software operating systems like Android and the applications that they run, commonly referred to as “apps.” Over the past few years, we have seen a boom in the popularity of mobile devices and mobile apps that run on these devices. Thus, solving the challenges faced by stakeholders such as mobile app developers, users, and platform owners (such as Apple/BlackBerry/Google/Microsoft) could create quite an impact.},
  isbn          = {978-0-12-804206-9},
}

@Article{10.1145/3130935,
  author        = {Li, Yuanchun and Jia, Baoxiong and Guo, Yao and Chen, Xiangqun},
  title         = {Mining User Reviews for Mobile App Comparisons},
  journal       = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
  year          = {2017},
  volume        = {1},
  number        = {3},
  month         = sep,
  __markedentry = {[jacekdabrowski:2]},
  address       = {New York, NY, USA},
  articleno     = {Article 75},
  issue_date    = {September 2017},
  keywords      = {Mobile application, user review, text processing, comparative opinion},
  numpages      = {15},
  publisher     = {ACM},
}

@Article{CHEN2019100889,
  author        = {Runyu Chen and Qili Wang and Wei Xu},
  title         = {Mining user requirements to facilitate mobile app quality upgrades with big data},
  journal       = {Electronic Commerce Research and Applications},
  year          = {2019},
  volume        = {38},
  pages         = {100889},
  __markedentry = {[jacekdabrowski:2]},
  abstract      = {A domain-dependent customer requirements mining framework to facilitate mobile app quality upgrades is proposed in this paper. We develop a new ranking model to rank the importance of different customer requirements by considering both the rating data and review data. We prove the effectiveness in terms of product quality improvements based on 265 version update cases for 15 popular mobile apps. As there is little research regarding identifying the business value of customer requirements mining, this study can be highly beneficial to the further development of research concerning the business value of adopting online customer requirements for product improvements.},
  issn          = {1567-4223},
}

@InProceedings{8048891,
  author        = {Z. {Kurtanović} and W. {Maalej}},
  title         = {Mining User Rationale from Software Reviews},
  booktitle     = {2017 IEEE 25th International Requirements Engineering Conference (RE)},
  year          = {2017},
  pages         = {61-70},
  month         = {Sep.},
  __markedentry = {[jacekdabrowski:2]},
  abstract      = {Rationale refers to the reasoning and justification behind human decisions, opinions, and beliefs. In software engineering, rationale management focuses on capturing design and requirements decisions and on organizing and reusing project knowledge. This paper takes a different view on rationale written by users in online reviews. We studied 32,414 reviews for 52 software applications in the Amazon Store. Through a grounded theory approach and peer content analysis, we investigated how users argue and justify their decisions, e.g. about upgrading, installing, or switching software applications. We also studied the occurrence frequency of rationale concepts such as issues encountered or alternatives considered in the reviews and found that assessment criteria like performance, compatibility, and usability represent the most pervasive concept. We then used the truth set of manually labeled review sentences to explore how accurately we can mine rationale concepts from the reviews. Support Vector Classifier, Naive Bayes, and Logistic Regression, trained on the review metadata, syntax tree of the review text, and influential terms, achieved a precision around 80% for predicting sentences with alternatives and decisions, with top recall values of 98%. On the review level, precision was up to 13% higher with recall values reaching 99%. We discuss the findings and the rationale importance for supporting deliberation in user communities and synthesizing the reviews for developers.},
  issn          = {2332-6441},
  keywords      = {Bayes methods;data mining;formal specification;meta data;regression analysis;software engineering;software maintenance;support vector machines;text analysis;human decisions;software engineering;rationale management;requirements decisions;online reviews;Amazon Store;grounded theory approach;peer content analysis;switching software applications;rationale concepts;pervasive concept;manually labeled review sentences;review metadata;user communities;software reviews;project knowledge;user rationale mining;review text syntax tree;support vector classifier;Naive Bayes;logistic regression;Encoding;Syntactics;Metadata;Requirements engineering;Software reviews;Usability;App Analytics;Rationale;Review Mining},
}

@InProceedings{10.1109/ASE.2015.85,
  author        = {Vu, Phong Minh and Nguyen, Tam The and Pham, Hung Viet and Nguyen, Tung Thanh},
  title         = {Mining User Opinions in Mobile App Reviews: A Keyword-Based Approach},
  booktitle     = {Proceedings of the 30th IEEE/ACM International Conference on Automated Software Engineering},
  year          = {2015},
  series        = {ASE ’15},
  pages         = {749–459},
  publisher     = {IEEE Press},
  __markedentry = {[jacekdabrowski:2]},
  isbn          = {9781509000241},
  keywords      = {keyword, opinion mining, review analysis},
  location      = {Lincoln, Nebraska},
  numpages      = {11},
}

@Article{DBLP:journals/ese/JhaM19,
  author        = {Nishant Jha and Anas Mahmoud},
  title         = {Mining non-functional requirements from App store reviews},
  journal       = {Empirical Software Engineering},
  year          = {2019},
  volume        = {24},
  number        = {6},
  pages         = {3659--3695},
  __markedentry = {[jacekdabrowski:2]},
  bibsource     = {dblp computer science bibliography, https://dblp.org},
  biburl        = {https://dblp.org/rec/bib/journals/ese/JhaM19},
  timestamp     = {Thu, 19 Dec 2019 09:26:48 +0100},
}

@Article{MALIK2016168,
  author        = {Haroon Malik and Elhadi M. Shakshuki},
  title         = {Mining Collective Opinions for Comparison of Mobile Apps},
  journal       = {Procedia Computer Science},
  year          = {2016},
  volume        = {94},
  pages         = {168 - 175},
  note          = {The 11th International Conference on Future Networks and Communications (FNC 2016) / The 13th International Conference on Mobile Systems and Pervasive Computing (MobiSPC 2016) / Affiliated Workshops},
  __markedentry = {[jacekdabrowski:2]},
}

@InProceedings{8560133,
  author        = {G. {Tong} and B. {Guo} and O. {Yi} and Y. {Zhiwen}},
  title         = {Mining and Analyzing User Feedback from App Reviews: An Econometric Approach},
  booktitle     = {2018 IEEE SmartWorld, Ubiquitous Intelligence Computing, Advanced Trusted Computing, Scalable Computing Communications, Cloud Big Data Computing, Internet of People and Smart City Innovation (SmartWorld/SCALCOM/UIC/ATC/CBDCom/IOP/SCI)},
  year          = {2018},
  pages         = {841-848},
  month         = {Oct},
  __markedentry = {[jacekdabrowski:2]},
  issn          = {null},
  keywords      = {data mining;econometrics;mobile computing;socio-economic effects;text analysis;app downloads;app reviews;app developers;complained app problems;mobile application distribution platforms;downloaded apps;app users;user reviews;user experience;mobile applications;user feedback;econometric methodologies;text mining techniques;econometric approach;Google Play;Apple Store;app review, text mining, econometric analysis},
}

@InProceedings{6149403,
  author        = {M. {Goul} and O. {Marjanovic} and S. {Baxley} and K. {Vizecky}},
  title         = {Managing the Enterprise Business Intelligence App Store: Sentiment Analysis Supported Requirements Engineering},
  booktitle     = {2012 45th Hawaii International Conference on System Sciences},
  year          = {2012},
  pages         = {4168-4177},
  month         = {Jan},
  __markedentry = {[jacekdabrowski:2]},
  abstract      = {This paper posits that an app store delivery model for enterprise business intelligence is inevitable due to compelling business and technology drivers. A model of how employees will adopt BI apps is advanced based on theoretical foundations and recent thinking regarding how IT artifacts are becoming perceived of as "social actors within one's network." The theory cited asserts that individual's resource management instincts impact sentiment. Repeated app usage is clarified as ongoing appropriation. Actual app store review data is used to test the proposition that sentiment analysis can aid in addressing current practice bottlenecks in requirements engineering. A sentiment analysis tool suite is applied to over 5000 reviews of productivity apps as a proof of concept. Findings support that sentiment analysis can address current bottlenecks to requirements engineering, but that certain types of reviews tend to elude algorithmic analysis. Future needs for sentiment analysis algorithms in the space are suggested.},
  issn          = {1530-1605},
  keywords      = {competitive intelligence;mobile computing;social aspects of automation;systems analysis;enterprise business intelligence app store;sentiment analysis supported requirements engineering;app store delivery model;technology drivers;business drivers;social actors;app store review data;algorithmic analysis;Bismuth;Context;Business;Productivity;Software;Documentation;Stress;Business Intelligence;Mobile BI;Business Intelligence App Store},
}

@InProceedings{8054841,
  author        = {Z. S. H. {Abad} and S. D. V. {Sims} and A. {Cheema} and M. B. {Nasir} and P. {Harisinghani}},
  title         = {Learn More, Pay Less! Lessons Learned from Applying the Wizard-of-Oz Technique for Exploring Mobile App Requirements},
  booktitle     = {2017 IEEE 25th International Requirements Engineering Conference Workshops (REW)},
  year          = {2017},
  pages         = {132-138},
  month         = {Sep.},
  __markedentry = {[jacekdabrowski:2]},
  abstract      = {Mobile apps have exploded in popularity, encouraging developers to provide content to the massive user base of the main app stores. Although there exist automated techniques that can classify user comments into various topics with high levels of precision, recent studies have shown that the top apps in the app stores do not have customer ratings that directly correlate with the app's success. This implies that no single requirements elicitation technique can cover the full depth required to produce a successful product and that applying alternative requirements gathering techniques can lead to success when these two are combined. Since user involvement has been found to be the most impactful contribution to project success, in this paper we will explore how the Wizard-of-Oz (WOz) technique and user reviews available in Google Play, can be integrated to produce a product that meets the demand of more stakeholders than either method alone. To compare the role of early interactive requirements specification and app reviews, we conducted two studies: (i) a case study analysis on 13 mobile app development teams who used very early stages Requirements Engineering (RE) by applying WOz, and (ii) a study analyzing 40 (70, 592 reviews) similar mobile apps on Google Play. The results of both studies show that while each of WOz and app review analysis techniques can be applied to capture specific types of requirements, an integrated process including both methods would eliminate the communication gap between users and developers at early stages of the development process and mitigates the risk of requirements change in later stages.},
  issn          = {null},
  keywords      = {formal specification;mobile computing;systems analysis;mobile app Requirements;main app stores;user comments;customer ratings;WOz;user reviews;Google Play;app reviews;requirements elicitation;Requirements Engineering;wizard-of-oz;interactive requirements specification;RE;Mobile communication;Tools;Usability;Stakeholders;Google;Data analysis;Requirements Engineering;Requirements Elicitation;Wizard-of-Oz;Empirical Study;Prototyping;Mobile App Development},
}

@InProceedings{10.1145/3236024.3264595,
  author        = {Gao, Cuiyun and Zeng, Jichuan and Lo, David and Lin, Chin-Yew and Lyu, Michael R. and King, Irwin},
  title         = {INFAR: Insight Extraction from App Reviews},
  booktitle     = {Proceedings of the 2018 26th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
  year          = {2018},
  series        = {ESEC/FSE 2018},
  pages         = {904–907},
  address       = {New York, NY, USA},
  publisher     = {ACM},
  __markedentry = {[jacekdabrowski:2]},
  isbn          = {9781450355735},
  keywords      = {insight extraction, App review, review topic},
  location      = {Lake Buena Vista, FL, USA},
  numpages      = {4},
}

@InProceedings{6912257,
  author        = {E. {Guzman} and W. {Maalej}},
  title         = {How Do Users Like This Feature? A Fine Grained Sentiment Analysis of App Reviews},
  booktitle     = {2014 IEEE 22nd International Requirements Engineering Conference (RE)},
  year          = {2014},
  pages         = {153-162},
  month         = {Aug},
  __markedentry = {[jacekdabrowski:2]},
  abstract      = {App stores allow users to submit feedback for downloaded apps in form of star ratings and text reviews. Recent studies analyzed this feedback and found that it includes information useful for app developers, such as user requirements, ideas for improvements, user sentiments about specific features, and descriptions of experiences with these features. However, for many apps, the amount of reviews is too large to be processed manually and their quality varies largely. The star ratings are given to the whole app and developers do not have a mean to analyze the feedback for the single features. In this paper we propose an automated approach that helps developers filter, aggregate, and analyze user reviews. We use natural language processing techniques to identify fine-grained app features in the reviews. We then extract the user sentiments about the identified features and give them a general score across all reviews. Finally, we use topic modeling techniques to group fine-grained features into more meaningful high-level features. We evaluated our approach with 7 apps from the Apple App Store and Google Play Store and compared its results with a manually, peer-conducted analysis of the reviews. On average, our approach has a precision of 0.59 and a recall of 0.51. The extracted features were coherent and relevant to requirements evolution tasks. Our approach can help app developers to systematically analyze user opinions about single features and filter irrelevant reviews.},
  issn          = {2332-6441},
  keywords      = {feature extraction;formal specification;information filtering;Internet;natural language processing;fine grained sentiment analysis;app reviews;app stores;user feedback;downloaded apps;star ratings;text reviews;app developers;user requirements;user sentiments;user reviews filter;user reviews aggregate;user reviews analyze;natural language processing techniques;fine-grained app features;topic modeling techniques;Apple App Store;Google Play Store;peer-conducted analysis;features extraction;requirements evolution tasks;Feature extraction;Encoding;Google;Sentiment analysis;Manuals;Dictionaries;Educational institutions},
}

@InProceedings{7332474,
  author        = {S. {Panichella} and A. {Di Sorbo} and E. {Guzman} and C. A. {Visaggio} and G. {Canfora} and H. C. {Gall}},
  title         = {How can i improve my app? Classifying user reviews for software maintenance and evolution},
  booktitle     = {2015 IEEE International Conference on Software Maintenance and Evolution (ICSME)},
  year          = {2015},
  pages         = {281-290},
  month         = {Sep.},
  __markedentry = {[jacekdabrowski:2]},
  issn          = {null},
  keywords      = {natural language processing;pattern classification;software maintenance;text analysis;user review classification;software maintenance;software evolution;app stores;review comments;star ratings;user feedback identification;app review classification;natural language processing;text analysis;sentiment analysis;Taxonomy;Software maintenance;Feature extraction;Natural language processing;Mobile communication;Maintenance engineering;Text analysis;User Reviews;Mobile Applications;Natural Language Processing;Sentiment Analysis;Text classification},
}

@InProceedings{8920629,
  author        = {E. {Guzman} and A. {Paredes Rojas}},
  title         = {Gender and User Feedback: An Exploratory Study},
  booktitle     = {2019 IEEE 27th International Requirements Engineering Conference (RE)},
  year          = {2019},
  pages         = {381-385},
  month         = {Sep.},
  __markedentry = {[jacekdabrowski:2]},
  issn          = {1090-705X},
  keywords      = {Software;Timing;Computer bugs;Australia;Databases;Data mining;Manuals;User Feedback, Feedback Analysis, App Reviews, Gender Bias, Algorithm Bias, Software Evolution, Requirements Elicitation},
}

@InProceedings{10.1145/2993259.2993267,
  author        = {Shah, Faiz Ali and Sabanin, Yevhenii and Pfahl, Dietmar},
  title         = {Feature-Based Evaluation of Competing Apps},
  booktitle     = {Proceedings of the International Workshop on App Market Analytics},
  year          = {2016},
  series        = {WAMA 2016},
  pages         = {15–21},
  address       = {New York, NY, USA},
  publisher     = {ACM},
  __markedentry = {[jacekdabrowski:2]},
  isbn          = {9781450343985},
  keywords      = {App market analysis, feature extraction, sentiment analysis},
  location      = {Seattle, WA, USA},
  numpages      = {7},
}

@InProceedings{6980228,
  author        = {E. {Guzman} and P. {Bhuvanagiri} and B. {Bruegge}},
  title         = {FAVe: Visualizing User Feedback for Software Evolution},
  booktitle     = {2014 Second IEEE Working Conference on Software Visualization},
  year          = {2014},
  pages         = {167-171},
  month         = {Sep.},
  __markedentry = {[jacekdabrowski:2]},
  abstract      = {App users can submit feedback about downloaded apps by writing review comments and giving star ratings directly in the distribution platforms. Previous research has shown that this type of feedback contains important information for software evolution. However, in the case of the most popular apps, the amount of received feedback and its unstructured nature can produce difficulties in its analysis. We present an interactive user feedback visualization which displays app reviews from four different points of view: general, review based, feature based and topic-feature based. We conducted a study which visualized 2009 reviews from the Dropbox app available in the App Store. Participants considered the approach useful for software evolution tasks as they found it could aid developers and analysts get an overview of the most and least popular app features, and to prioritize their work. While using different strategies to find relevant information during the study, most participants came to the same conclusions regarding the user reviews and assigned tasks.},
  issn          = {null},
  keywords      = {data visualisation;interactive systems;software engineering;FAVe;interactive user feedback visualization;software evolution;downloaded app feedback;app reviews;Dropbox app;App Store;Visualization;Feature extraction;Software;Data mining;Sentiment analysis;Navigation;Image color analysis},
}

@InProceedings{10.1145/2468356.2468681,
  author        = {Oh, Jeungmin and Kim, Daehoon and Lee, Uichin and Lee, Jae-Gil and Song, Junehwa},
  title         = {Facilitating Developer-User Interactions with Mobile App Review Digests},
  booktitle     = {CHI ’13 Extended Abstracts on Human Factors in Computing Systems},
  year          = {2013},
  series        = {CHI EA ’13},
  pages         = {1809–1814},
  address       = {New York, NY, USA},
  publisher     = {ACM},
  __markedentry = {[jacekdabrowski:2]},
  isbn          = {9781450319522},
  keywords      = {user-centered design, mobile apps, user involvements, comment classification, app review},
  location      = {Paris, France},
  numpages      = {6},
}

@InProceedings{8215693,
  author        = {Y. {Wang} and H. {Wang} and H. {Fang}},
  title         = {Extracting User-Reported Mobile Application Defects from Online Reviews},
  booktitle     = {2017 IEEE International Conference on Data Mining Workshops (ICDMW)},
  year          = {2017},
  pages         = {422-429},
  month         = {Nov},
  __markedentry = {[jacekdabrowski:2]},
  issn          = {2375-9259},
  keywords      = {feature extraction;mobile computing;support vector machines;text analysis;word processing;user-reported mobile application defects;online reviews;mobile application reviews;software artifacts;user-reported implementation defects;review content;functional defects;structural SVM model;detailed defect description extraction;Apple App Store;mobile app reviews;Mobile communication;Software;Feature extraction;Training;Data mining;Mobile applications;Data models},
}

@InProceedings{7774515,
  author        = {Y. {Man} and C. {Gao} and M. R. {Lyu} and J. {Jiang}},
  title         = {Experience Report: Understanding Cross-Platform App Issues from User Reviews},
  booktitle     = {2016 IEEE 27th International Symposium on Software Reliability Engineering (ISSRE)},
  year          = {2016},
  pages         = {138-149},
  month         = {Oct},
  __markedentry = {[jacekdabrowski:2]},
  abstract      = {App developers publish apps on different platforms, such as Google Play, App Store, and Windows Store, to maximize the user volumes and potential revenues. Due to the different characteristics of the platforms and the different user preference (e.g., Android is more customized than iOS), app testing cases on these three platforms should also be designed differently. Comprehensive app testing can be time-consuming for developers. Therefore, understanding the differences of the app issues on these platforms can facilitate the testing process. In this paper, we propose a novel framework named CrossMiner to analyze the essential app issues and explore whether the app issues exhibit differently on the three platforms. Based on five million user reviews, the framework automatically captures the distributions of seven app issues, i.e., "battery", "crash", "memory", "network", "privacy", "spam", and "UI". We discover that the apps for different platforms indeed generate different issue distributions, which can be employed by app developers to schedule and design the testing cases. The verification based on the official user forums also demonstrates the effectiveness of our framework. Furthermore, we also identify that the issues related to "crash" and "network" are more concerned by users than the other issues on these three platforms. To assist developers in gaining a deep insight on the user issues, we also prioritize the user reviews corresponding to the issues. Overall, we aim at understanding the differences of issues on different platforms and facilitating the testing process for app developers.},
  issn          = {2332-6549},
  keywords      = {mobile computing;cross platform app issues;user reviews;user volumes;Android;iOS;testing process;CrossMiner;Testing;Google;Computer crashes;Mars;Mobile communication;Batteries;Privacy;user feedback;data mining;user reviews;mobile application},
}

@InProceedings{7972723,
  author        = {S. {Mujahid} and G. {Sierra} and R. {Abdalkareem} and E. {Shihab} and W. {Shang}},
  title         = {Examining User Complaints of Wearable Apps: A Case Study on Android Wear},
  booktitle     = {2017 IEEE/ACM 4th International Conference on Mobile Software Engineering and Systems (MOBILESoft)},
  year          = {2017},
  pages         = {96-99},
  month         = {May},
  __markedentry = {[jacekdabrowski:2]},
  abstract      = {Wearable apps are becoming increasingly popular in recent years. However, to date, very few studies examined the issues that wearable apps face. Prior studies showed that user reviews contain a plethora of insights that can be used to understand quality issues and help developers build better quality mobile apps. Therefore, in this paper, we mine user reviews in order to understand the user complaints of wearable apps. We manually sample and categorize 589 reviews from 6 Android wearable apps. Our findings indicate that the most frequent complaints are related to functional errors, lack of functionality, and cost. Our results are useful to the wearable developer community since they highlight the issues that users face and care most about.},
  issn          = {null},
  keywords      = {mobile computing;software quality;wearable computers;user complaints;user reviews;quality mobile apps;Android wearable apps;functional errors;cost;wearable developer community;Androids;Humanoid robots;Mobile communication;Face;Batteries;Google;Focusing;Wear Apps;Users' Reviews;Google Play Store;Empirical Studies},
}

@InProceedings{10.1109/ASE.2015.88,
  author        = {Guzman, Emitza and El-Halaby, Muhammad and Bruegge, Bernd},
  title         = {Ensemble Methods for App Review Classification: An Approach for Software Evolution},
  booktitle     = {Proceedings of the 30th IEEE/ACM International Conference on Automated Software Engineering},
  year          = {2015},
  series        = {ASE ’15},
  pages         = {771–776},
  publisher     = {IEEE Press},
  __markedentry = {[jacekdabrowski:2]},
  isbn          = {9781509000241},
  location      = {Lincoln, Nebraska},
  numpages      = {6},
}

@InProceedings{10.1109/ICSE-SEIP.2019.00040,
  author        = {Gao, Cuiyun and Zheng, Wujie and Deng, Yuetang and Lo, David and Zeng, Jichuan and Lyu, Michael R. and King, Irwin},
  title         = {Emerging App Issue Identification from User Feedback: Experience on WeChat},
  booktitle     = {Proceedings of the 41st International Conference on Software Engineering: Software Engineering in Practice},
  year          = {2019},
  series        = {ICSE-SEIP ’19},
  pages         = {279–288},
  publisher     = {IEEE Press},
  __markedentry = {[jacekdabrowski:2]},
  keywords      = {mobile apps, emerging issue detection, app reviews, anomaly},
  location      = {Montreal, Quebec, Canada},
  numpages      = {10},
}

@InProceedings{8860063,
  author        = {P. {Weichbroth} and A. {Baj-Rogowska}},
  title         = {Do Online Reviews Reveal Mobile Application Usability and User Experience? The Case of WhatsApp},
  booktitle     = {2019 Federated Conference on Computer Science and Information Systems (FedCSIS)},
  year          = {2019},
  pages         = {747-754},
  month         = {Sep.},
  __markedentry = {[jacekdabrowski:2]},
  issn          = {2300-5963},
  keywords      = {Internet;mobile computing;natural language processing;text analysis;Web sites;online stores;informal online app reviews;viral form;word-of-mouth;user experience;eWOM WhatsApp data;original users;genuine UUX issues;hardware devices;mobile applications;communication platform;online reviews;mobile application usability;Usability;Mobile applications;User experience;Sentiment analysis;Feature extraction;Data mining;Dictionaries},
}

@InProceedings{10.1109/ICSE-SEIP.2019.00041,
  author        = {Maalej, Walid and Nayebi, Maleknaz and Ruhe, Guenther},
  title         = {Data-Driven Requirements Engineering: An Update},
  booktitle     = {Proceedings of the 41st International Conference on Software Engineering: Software Engineering in Practice},
  year          = {2019},
  series        = {ICSE-SEIP ’19},
  pages         = {289–290},
  publisher     = {IEEE Press},
  __markedentry = {[jacekdabrowski:2]},
  keywords      = {data analytics, mining software repositories, stakeholders, feature extraction, requirements engineering},
  location      = {Montreal, Quebec, Canada},
  numpages      = {2},
}

@Article{DBLP:journals/jcst/ZhangHJH17,
  author        = {Li Zhang and Xin{-}Yue Huang and Jing Jiang and Ya{-}Kun Hu},
  title         = {CSLabel: An Approach for Labelling Mobile App Reviews},
  journal       = {J. Comput. Sci. Technol.},
  year          = {2017},
  volume        = {32},
  number        = {6},
  pages         = {1076--1089},
  __markedentry = {[jacekdabrowski:2]},
  bibsource     = {dblp computer science bibliography, https://dblp.org},
  biburl        = {https://dblp.org/rec/bib/journals/jcst/ZhangHJH17},
  timestamp     = {Wed, 20 Feb 2019 06:31:00 +0100},
}

@Article{PALOMBA2018143,
  author        = {Fabio Palomba and Mario Linares-Vásquez and Gabriele Bavota and Rocco Oliveto and Massimiliano Di Penta and Denys Poshyvanyk and Andrea De Lucia},
  title         = {Crowdsourcing user reviews to support the evolution of mobile apps},
  journal       = {Journal of Systems and Software},
  year          = {2018},
  volume        = {137},
  pages         = {143 - 162},
  __markedentry = {[jacekdabrowski:2]},
  abstract      = {In recent software development and distribution scenarios, app stores are playing a major role, especially for mobile apps. On one hand, app stores allow continuous releases of app updates. On the other hand, they have become the premier point of interaction between app providers and users. After installing/updating apps, users can post reviews and provide ratings, expressing their level of satisfaction with apps, and possibly pointing out bugs or desired features. In this paper we empirically investigate—by performing a study on the evolution of 100 open source Android apps and by surveying 73 developers—to what extent app developers take user reviews into account, and whether addressing them contributes to apps’ success in terms of ratings. In order to perform the study, as well as to provide a monitoring mechanism for developers and project managers, we devised an approach, named CRISTAL, for tracing informative crowd reviews onto source code changes, and for monitoring the extent to which developers accommodate crowd requests and follow-up user reactions as reflected in their ratings. The results of our study indicate that (i) on average, half of the informative reviews are addressed, and over 75% of the interviewed developers claimed to take them into account often or very often, and that (ii) developers implementing user reviews are rewarded in terms of significantly increased user ratings.},
  issn          = {0164-1212},
  keywords      = {Mobile app evolution, User reviews, Mining app stores, Empirical study},
}

@Article{MALIK2018,
  author        = {Haroon Malik and Elhadi M. Shakshuki and Wook-Sung Yoo},
  title         = {Comparing mobile apps by identifying ‘Hot’ features},
  journal       = {Future Generation Computer Systems},
  year          = {2018},
  __markedentry = {[jacekdabrowski:2]},
  abstract      = {User review is a crucial component of open mobile app market such as the Google Play Store. These markets allow users to submit feedback for downloaded apps in the form of (a) star ratings and (b) opinions in the form of text reviews. Users read these reviews in order to gain insight into the app before they buy or download it. The user opinion about the product also influences on the purchasing decisions of potential users; that in trun, plays a key role in the generation of revenue for the developers. The mobile apps can contain large volume of reviews, which make it nearlyimpossible for a user to skim through thousands of reviews to find the opinion of other users about the features which interest them the most. Towards this end, we propose a methodology to automatically extract the features of an app from its corresponding reviews using machine learning technique. Moreover, our proposed methodology would aid users to compare the features across multiple apps, using the sentiments, expressed in their associated reviews. The proposed methodology can be used to understand a user’s preference for a certain mobile app and could uncover the reasons why users prefer one app over another.},
  issn          = {0167-739X},
  keywords      = {Opinion mining, Google play store, Sentiment analysis},
}

@InProceedings{8933719,
  author        = {C. {Stanik} and M. {Haering} and W. {Maalej}},
  title         = {Classifying Multilingual User Feedback using Traditional Machine Learning and Deep Learning},
  booktitle     = {2019 IEEE 27th International Requirements Engineering Conference Workshops (REW)},
  year          = {2019},
  pages         = {220-226},
  month         = {Sep.},
  __markedentry = {[jacekdabrowski:2]},
  abstract      = {With the rise of social media like Twitter and of software distribution platforms like app stores, users got various ways to express their opinion about software products. Popular software vendors get user feedback thousandfold per day. Research has shown that such feedback contains valuable information for software development teams such as problem reports or feature and support inquires. Since the manual analysis of user feedback is cumbersome and hard to manage many researchers and tool vendors suggested to use automated analyses based on traditional supervised machine learning approaches. In this work, we compare the results of traditional machine learning and deep learning in classifying user feedback in English and Italian into problem reports, inquiries, and irrelevant. Our results show that using traditional machine learning, we can still achieve comparable results to deep learning, although we collected thousands of labels.},
  issn          = {null},
  keywords      = {Data-Driven Requirements, Data Mining, Social Media Analytics, Machine Learning, Deep Learning},
}

@InProceedings{8850962,
  author        = {K. {Phetrungnapha} and T. {Senivongse}},
  title         = {Classification of Mobile Application User Reviews for Generating Tickets on Issue Tracking System},
  booktitle     = {2019 12th International Conference on Information Communication Technology and System (ICTS)},
  year          = {2019},
  pages         = {229-234},
  month         = {July},
  __markedentry = {[jacekdabrowski:2]},
  issn          = {null},
  keywords      = {Bayes methods;data mining;decision trees;learning (artificial intelligence);meta data;mobile computing;pattern classification;program debugging;sentiment analysis;user feedback;Play Store;issue tracking system;user review classification;text classification;review metadata;Jira ticket generating tool;review comments;duplicate user reviews;corresponding bug report;mobile development team;mobile application user reviews;mobile application development;Apple App Store;GooglePlay Store;user reviews classification;tickets generation;mobile application classification;natural language processing;sentiment analysis;LinearSVC;logistic regression;ensemble methods;Computer bugs;Mobile applications;Tools;Machine learning algorithms;Decision trees;Logistics;Maintenance engineering;user reviews;issue tracking system;text classification;text similarity;text summarization;machine learning;natural language processing},
}

@InProceedings{10.1145/3239235.3267428,
  author        = {Wang, Chong and Zhang, Fan and Liang, Peng and Daneva, Maya and van Sinderen, Marten},
  title         = {Can App Changelogs Improve Requirements Classification from App Reviews? An Exploratory Study},
  booktitle     = {Proceedings of the 12th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement},
  year          = {2018},
  series        = {ESEM ’18},
  address       = {New York, NY, USA},
  publisher     = {ACM},
  __markedentry = {[jacekdabrowski:2]},
  articleno     = {Article 43},
  isbn          = {9781450358231},
  keywords      = {machine learning, app reviews, requirements analysis, data-driven requirements engineering, app changelogs},
  location      = {Oulu, Finland},
  numpages      = {4},
}

@InProceedings{7320414,
  author        = {W. {Maalej} and H. {Nabil}},
  title         = {Bug report, feature request, or simply praise? On automatically classifying app reviews},
  booktitle     = {2015 IEEE 23rd International Requirements Engineering Conference (RE)},
  year          = {2015},
  pages         = {116-125},
  month         = {Aug},
  __markedentry = {[jacekdabrowski:2]},
  issn          = {2332-6441},
  keywords      = {data mining;natural language processing;pattern classification;probability;software reviews;string matching;text analysis;bug report;app reviews classification;App stores;Google Play;Apple AppStore;several probabilistic techniques;review metadata;star rating;user experiences;feature requests;text classification;natural language processing;sentiment analysis techniques;string matching;multiple binary classifiers;multiclass classifiers;review analytics tool design;Metadata;Google;Accuracy;Training;Computer crashes;Natural language processing;Machine learning algorithms},
}

@InProceedings{8330252,
  author        = {L. {Pelloni} and G. {Grano} and A. {Ciurumelea} and S. {Panichella} and F. {Palomba} and H. C. {Gall}},
  title         = {BECLoMA: Augmenting stack traces with user review information},
  booktitle     = {2018 IEEE 25th International Conference on Software Analysis, Evolution and Reengineering (SANER)},
  year          = {2018},
  pages         = {522-526},
  month         = {March},
  __markedentry = {[jacekdabrowski:2]},
  abstract      = {Mobile devices such as smartphones, tablets and wearables are changing the way we do things, radically modifying our approach to technology. To sustain the high competition characterizing the mobile market, developers need to deliver high quality applications in a short release cycle. To reveal and fix bugs as soon as possible, researchers and practitioners proposed tools to automate the testing process. However, such tools generate a high number of redundant inputs, lacking of contextual information and generating reports difficult to analyze. In this context, the content of user reviews represents an unmatched source for developers seeking for defects in their applications. However, no prior work explored the adoption of information available in user reviews for testing purposes. In this demo we present BECLOMA, a tool to enable the integration of user feedback in the testing process of mobile apps. BECLOMA links information from testing tools and user reviews, presenting to developers an augmented testing report combining stack traces with user reviews information referring to the same crash. We show that BECLOMA facilitates not only the diagnosis and fix of app bugs, but also presents additional benefits: it eases the usage of testing tools and automates the analysis of user reviews from the Google Play Store.},
  issn          = {null},
  keywords      = {mobile computing;program debugging;smart phones;user review information;mobile devices;mobile market;testing process;contextual information;testing purposes;user feedback;mobile apps;BECLOMA links information;testing tools;augmented testing report;user reviews information;stack trace augmentation;Tools;Testing;Computer bugs;Crawlers;Google;Androids;Automated Software Testing;Mobile Applications;User Reviews Analysis},
}

@InProceedings{10.1145/2541016.2541067,
  author        = {Hoon, Leonard and Vasa, Rajesh and Martino, Gloria Yoanita and Schneider, Jean-Guy and Mouzakis, Kon},
  title         = {Awesome! Conveying Satisfaction on the App Store},
  booktitle     = {Proceedings of the 25th Australian Computer-Human Interaction Conference: Augmentation, Application, Innovation, Collaboration},
  year          = {2013},
  series        = {OzCHI ’13},
  pages         = {229–232},
  address       = {New York, NY, USA},
  publisher     = {ACM},
  __markedentry = {[jacekdabrowski:2]},
  isbn          = {9781450325257},
  keywords      = {user reviews, mobile apps, text mining, user vocabulary, app store, review rating systems},
  location      = {Adelaide, Australia},
  numpages      = {4},
}

@InProceedings{8054879,
  author        = {R. {Deocadez} and R. {Harrison} and D. {Rodriguez}},
  title         = {Automatically Classifying Requirements from App Stores: A Preliminary Study},
  booktitle     = {2017 IEEE 25th International Requirements Engineering Conference Workshops (REW)},
  year          = {2017},
  pages         = {367-371},
  month         = {Sep.},
  __markedentry = {[jacekdabrowski:2]},
  issn          = {null},
  keywords      = {learning (artificial intelligence);mobile computing;pattern classification;self-labeling algorithms;SemiSupervised Classification techniques;Automatic requirements classification;requirements classification;collected data;classical supervised techniques;SSC techniques;App Store;nonfunctional requirements;Niobium;Prediction algorithms;Training;Mobile communication;Text mining;Measurement;Semi-supervised Learning;Self-labeling algorithms;Mobile apps;Apps reviews},
}

@Article{SUN2017767,
  author        = {Zaoyi Sun and Zhiwei Ji and Pei Zhang and Chuansheng Chen and Xiuying Qian and Xin Du and Qun Wan},
  title         = {Automatic labeling of mobile apps by the type of psychological needs they satisfy},
  journal       = {Telematics and Informatics},
  year          = {2017},
  volume        = {34},
  number        = {5},
  pages         = {767 - 778},
  __markedentry = {[jacekdabrowski:2]},
  abstract      = {App usage is now a ubiquitous phenomenon, but little is known about what types of psychological needs are met by which apps. We proposed a method to label automatically mobile apps in terms of whether and to what extent they can satisfy users’ particular psychological needs. First, using the grounded theory approach, we conducted semi-structured in-depth interviews to identify types of needs associated with app usage. Substantive and theoretical coding of the data from the interviews as well as data from samples of app reviews yielded eight types of psychological needs app users had: utilitarian, low-cost, security, health, hedonic, social, cognitive, and self-actualization needs. Second, using the needs corpus (words and phrases) generated above, a classifier was trained using latent Dirichlet allocation (LDA) and support vector machine (SVM) algorithms to filter reviews in terms of whether they included needs-related comments. The classifier showed good performance. Finally, Labeled-LDA was used to automatically provide each review with multiple labels of the types of needs mentioned and the apps were analyzed for the different types of needs they satisfied.},
  issn          = {0736-5853},
}

@InProceedings{10.1145/3084226.3084241,
  author        = {Lu, Mengmeng and Liang, Peng},
  title         = {Automatic Classification of Non-Functional Requirements from Augmented App User Reviews},
  booktitle     = {Proceedings of the 21st International Conference on Evaluation and Assessment in Software Engineering},
  year          = {2017},
  series        = {EASE’17},
  pages         = {344–353},
  address       = {New York, NY, USA},
  publisher     = {ACM},
  __markedentry = {[jacekdabrowski:2]},
  isbn          = {9781450348041},
  keywords      = {Automatic Classification, Textual Semantics, User Reviews, Non-Functional Requirements},
  location      = {Karlskrona, Sweden},
  numpages      = {10},
}

@InProceedings{8931820,
  author        = {N. {Al Kilani} and R. {Tailakh} and A. {Hanani}},
  title         = {Automatic Classification of Apps Reviews for Requirement Engineering: Exploring the Customers Need from Healthcare Applications},
  booktitle     = {2019 Sixth International Conference on Social Networks Analysis, Management and Security (SNAMS)},
  year          = {2019},
  pages         = {541-548},
  month         = {Oct},
  __markedentry = {[jacekdabrowski:2]},
  issn          = {null},
  keywords      = {Requirements Engineering;User's Reviews;Data Annotation;Supervised Machine Learning;Text Classification},
}

@InProceedings{10.1145/3084226.3084246,
  author        = {Licorish, Sherlock A. and Savarimuthu, Bastin Tony Roy and Keertipati, Swetha},
  title         = {Attributes That Predict Which Features to Fix: Lessons for App Store Mining},
  booktitle     = {Proceedings of the 21st International Conference on Evaluation and Assessment in Software Engineering},
  year          = {2017},
  series        = {EASE’17},
  pages         = {108–117},
  address       = {New York, NY, USA},
  publisher     = {ACM},
  __markedentry = {[jacekdabrowski:2]},
  isbn          = {9781450348041},
  keywords      = {Requirements Engineering, Empirical Studies, Feature Prioritization, App Reviews, Text Mining},
  location      = {Karlskrona, Sweden},
  numpages      = {10},
}

@InProceedings{10.1145/2568225.2568263,
  author        = {Chen, Ning and Lin, Jialiu and Hoi, Steven C. H. and Xiao, Xiaokui and Zhang, Boshen},
  title         = {AR-Miner: Mining Informative Reviews for Developers from Mobile App Marketplace},
  booktitle     = {Proceedings of the 36th International Conference on Software Engineering},
  year          = {2014},
  series        = {ICSE 2014},
  pages         = {767–778},
  address       = {New York, NY, USA},
  publisher     = {ACM},
  __markedentry = {[jacekdabrowski:2]},
  isbn          = {9781450327565},
  keywords      = {user reviews, mobile application, User feedback, data mining},
  location      = {Hyderabad, India},
  numpages      = {12},
}

@Article{DBLP:journals/ese/NayebiCR18,
  author        = {Maleknaz Nayebi and Henry Cho and Guenther Ruhe},
  title         = {App store mining is not enough for app improvement},
  journal       = {Empirical Software Engineering},
  year          = {2018},
  volume        = {23},
  number        = {5},
  pages         = {2764--2794},
  __markedentry = {[jacekdabrowski:2]},
  bibsource     = {dblp computer science bibliography, https://dblp.org},
  biburl        = {https://dblp.org/rec/bib/journals/ese/NayebiCR18},
  timestamp     = {Wed, 14 Nov 2018 10:41:44 +0100},
}

@InProceedings{7965286,
  author        = {M. {Nayebi} and H. {Cho} and H. {Farrahi} and G. {Ruhe}},
  title         = {App Store Mining Is Not Enough},
  booktitle     = {2017 IEEE/ACM 39th International Conference on Software Engineering Companion (ICSE-C)},
  year          = {2017},
  pages         = {152-154},
  month         = {May},
  __markedentry = {[jacekdabrowski:2]},
  issn          = {null},
  keywords      = {data mining;mobile computing;social networking (online);app development;app evolution;app store reviews;app user feedback;social media;Twitter;mobile app development;app store mining;Computer bugs;Twitter;Software;Data mining;Conferences;Software engineering;Mobile communication;App store mining;Twitter;Mobile apps;Topic modeling;Machine learning},
}

@Article{doi:10.1002/spe.2693,
  author        = {Liu, Yuzhou and Liu, Lei and Liu, Huaxiao and Yin, Xinglong},
  title         = {App store mining for iterative domain analysis: Combine app descriptions with user reviews},
  journal       = {Software: Practice and Experience},
  year          = {2019},
  volume        = {49},
  number        = {6},
  pages         = {1013-1040},
  note          = {SPE-19-0009.R1},
  __markedentry = {[jacekdabrowski:2]},
  abstract      = {Summary Compared with traditional software, the domain analysis of apps is conducted not only in the early stage of software development to gain knowledge of a particular domain but also runs throughout each iteration of apps to help developers understand evolution trends of the domain for maintaining their competitiveness. In this paper, we propose an approach to analyze app descriptions combined with reviews in App stores automatically and construct a feature-based domain state model (FDSM) in the form of state machine to support the domain analysis of apps. In FDSM, the domain knowledge up to a certain moment together is defined as a state. Initial state summarizes the high-level knowledge by gaining topics of app descriptions, whereas each transition is generated based on the information gained within one period of time and describes the change from the current state to the next one. Furthermore, user opinions in reviews are introduced into the model to quantify the value of information for helping developers get key domain knowledge efficiently. To validate the proposed approach, we conducted a series of experiments based on Google Play. The results show that FDSM can provide valuable information for supporting domain analysis, especially in the evolution process of apps.},
  keywords      = {app store mining, domain analysis, feature extraction, reviews analysis},
}

@InProceedings{10.1145/3121264.3121266,
  author        = {Grano, Giovanni and Di Sorbo, Andrea and Mercaldo, Francesco and Visaggio, Corrado A. and Canfora, Gerardo and Panichella, Sebastiano},
  title         = {Android Apps and User Feedback: A Dataset for Software Evolution and Quality Improvement},
  booktitle     = {Proceedings of the 2nd ACM SIGSOFT International Workshop on App Market Analytics},
  year          = {2017},
  series        = {WAMA 2017},
  pages         = {8–11},
  address       = {New York, NY, USA},
  publisher     = {ACM},
  __markedentry = {[jacekdabrowski:2]},
  isbn          = {9781450351584},
  keywords      = {Software Maintenance and Evolution, Mobile Applications, App Reviews, Software Quality},
  location      = {Paderborn, Germany},
  numpages      = {4},
}

@InProceedings{8835255,
  author        = {R. A. {Masrury} and {Fannisa} and A. {Alamsyah}},
  title         = {Analyzing Tourism Mobile Applications Perceived Quality using Sentiment Analysis and Topic Modeling},
  booktitle     = {2019 7th International Conference on Information and Communication Technology (ICoICT)},
  year          = {2019},
  pages         = {1-6},
  month         = {July},
  __markedentry = {[jacekdabrowski:2]},
  issn          = {null},
  keywords      = {data mining;mobile computing;sentiment analysis;travel industry;selected text analysis methods;online travel agent applications qualities;sentiment analysis method;international tourists;travel-related activities providers;mobile application quality;hidden information;topic modeling method;information platforms;text mining models;mobile application service quality dimensions;popular online travel agent mobile applications;tourism mobile applications perceived quality;MappSql dimensions;Sentiment analysis;Mobile applications;Analytical models;Companies;Text mining;Predictive models;Mobile Application Quality;Text Mining;User Satisfaction.},
}

@Article{doi:10.1002/smr.2112,
  author        = {Liu, Yuzhou and Liu, Lei and Liu, Huaxiao and Wang, Xiaoyu},
  title         = {Analyzing reviews guided by App descriptions for the software development and evolution},
  journal       = {Journal of Software: Evolution and Process},
  year          = {2018},
  volume        = {30},
  number        = {12},
  pages         = {e2112},
  note          = {e2112 JSME-17-0184.R2},
  __markedentry = {[jacekdabrowski:2]},
  abstract      = {Abstract Reviews in App stores are a massive and fast-growing data resource for developers to understand user experiences and their needs. Studies show that users often express their sentiments on App features in reviews, and this information is important for the development and evolution of Apps. To help developers gain such information efficiently, this paper proposes a method using App descriptions, another typical data in App stores, to guide the analysis of reviews. Firstly, we extract App features from descriptions, then summarize them to gain topics of App features as high-level information; the results are formalized as a topic-based domain model (TBDM). Secondly, we train classifiers of reviews based on the model to establish the relationships between user sentiments and App features. Finally, a quantified method is given to analyze the model based on developer preferences for recommending and summarizing reviews. To evaluate our approach, experiments were conducted using the App descriptions and reviews collected from Google Play. The results indicate that the approach can classify reviews to their related App features effectively (average F measure is 86.13\%), and provides useful information for overall analyzing App features in a domain and identifying (dis)advantages of an App.},
  keywords      = {App descriptions, review analysis, sentiment mining, topic modeling},
}

@Article{DBLP:journals/ese/McIlroyAKH16,
  author        = {Stuart McIlroy and Nasir Ali and Hammad Khalid and Ahmed E. Hassan},
  title         = {Analyzing and automatically labelling the types of user issues that are raised in mobile app reviews},
  journal       = {Empirical Software Engineering},
  year          = {2016},
  volume        = {21},
  number        = {3},
  pages         = {1067--1106},
  __markedentry = {[jacekdabrowski:2]},
  bibsource     = {dblp computer science bibliography, https://dblp.org},
  biburl        = {https://dblp.org/rec/bib/journals/ese/McIlroyAKH16},
  timestamp     = {Sun, 28 May 2017 13:22:43 +0200},
}

@InProceedings{10.5555/2486788.2486865,
  author        = {Carre\~{n}o, Laura V. G. and Winbladh, Kristina},
  title         = {Analysis of User Comments: An Approach for Software Requirements Evolution},
  booktitle     = {Proceedings of the 2013 International Conference on Software Engineering},
  year          = {2013},
  series        = {ICSE ’13},
  pages         = {582–591},
  publisher     = {IEEE Press},
  __markedentry = {[jacekdabrowski:2]},
  isbn          = {9781467330763},
  location      = {San Francisco, CA, USA},
  numpages      = {10},
}

@InProceedings{10.1145/3197231.3197236,
  author        = {Scoccia, Gian Luca and Ruberto, Stefano and Malavolta, Ivano and Autili, Marco and Inverardi, Paola},
  title         = {An Investigation into Android Run-Time Permissions from the End Users’ Perspective},
  booktitle     = {Proceedings of the 5th International Conference on Mobile Software Engineering and Systems},
  year          = {2018},
  series        = {MOBILESoft ’18},
  pages         = {45–55},
  address       = {New York, NY, USA},
  publisher     = {ACM},
  __markedentry = {[jacekdabrowski:2]},
  isbn          = {9781450357128},
  keywords      = {review analysis, apps, permissions, privacy, Android, security, opinion mining},
  location      = {Gothenburg, Sweden},
  numpages      = {11},
}

@Article{DBLP:journals/ese/MujahidSASS18,
  author        = {Suhaib Mujahid and Giancarlo Sierra and Rabe Abdalkareem and Emad Shihab and Weiyi Shang},
  title         = {An empirical study of Android Wear user complaints},
  journal       = {Empirical Software Engineering},
  year          = {2018},
  volume        = {23},
  number        = {6},
  pages         = {3476--3502},
  __markedentry = {[jacekdabrowski:2]},
  bibsource     = {dblp computer science bibliography, https://dblp.org},
  biburl        = {https://dblp.org/rec/bib/journals/ese/MujahidSASS18},
  timestamp     = {Wed, 29 May 2019 09:33:18 +0200},
}

@InProceedings{10.1145/3010915.3010976,
  author        = {Simmons, Andrew and Hoon, Leonard},
  title         = {Agree to Disagree: On Labelling Helpful App Reviews},
  booktitle     = {Proceedings of the 28th Australian Conference on Computer-Human Interaction},
  year          = {2016},
  series        = {OzCHI ’16},
  pages         = {416–420},
  address       = {New York, NY, USA},
  publisher     = {ACM},
  __markedentry = {[jacekdabrowski:2]},
  isbn          = {9781450346184},
  keywords      = {rating systems, mobile apps, helpful reviews, inter-rater agreement, text mining, reviews, recommender systems},
  location      = {Launceston, Tasmania, Australia},
  numpages      = {5},
}

@InProceedings{8500065,
  author        = {S. {Muñoz} and O. {Araque} and A. F. {Llamas} and C. A. {Iglesias}},
  title         = {A Cognitive Agent for Mining Bugs Reports, Feature Suggestions and Sentiment in a Mobile Application Store},
  booktitle     = {2018 4th International Conference on Big Data Innovations and Applications (Innovate-Data)},
  year          = {2018},
  pages         = {17-24},
  month         = {Aug},
  __markedentry = {[jacekdabrowski:2]},
  issn          = {null},
  keywords      = {cognitive systems;data mining;learning (artificial intelligence);mobile computing;program debugging;sentiment analysis;software quality;applications stores;ratings;software quality;textual reviews;cognitive computing technologies;smart agent;feature suggestions;sentiment;mobile app reviews;cognitive agent;feature request detection;agent implementation;mobile application store;distribution platforms;bugs reports mining;Computer bugs;Servers;Google;Natural languages;Data mining;Cognitive systems;Feature extraction;cognitive agent;review;app;bug;suggestions;sentiment analysis},
}

@Article{ZHANG201930,
  author        = {Jianzhang Zhang and Yinglin Wang and Tian Xie},
  title         = {Software feature refinement prioritization based on online user review mining},
  journal       = {Information and Software Technology},
  year          = {2019},
  volume        = {108},
  pages         = {30 - 34},
  __markedentry = {[jacekdabrowski:2]},
  abstract      = {Context
Online software reviews have provided a wealth of user feedback on software applications. User reviews along with ratings have been influential in a series of software engineering tasks e.g. software maintenance and release planning.
Objective
Our research aims to assist managers in prioritizing features to be refined in next release from the perspective of enhancing user ratings via mining online reviews.
Method
We first extract software features from user reviews and determine their probability distribution in each review with LDA. Then the ground truth rating of each feature is estimated by linear regression under the assumption that the software functionality rating is a convex combination of all feature ratings weighted by their distribution probabilities over the review. Finally, we formalize feature refinement prioritization as an optimization problem which maximizes user groupâs rating on the software functionality under the constraint of development budget.
Results
The proposed approach can use topic model to jointly extract features from user reviews semi-supervisedly and determine each featureâs weight in each userâs rating on the software functionality. The estimated ground truth ratings of all features reveal how reviewer group evaluate those features. Finally, we provide an illustrative example to demonstrate the key idea of our framework.
Conclusion
Our proposed framework is general to various software products with mass user reviews and semi-automatic without much human efforts and intervention. The frameworkâs interpretability helps managers better understand user feedback on the software functionality and make feature refinement plan for the upcoming releases.},
  issn          = {0950-5849},
}

@Article{8738898,
  author        = {D. {Martens} and W. {Maalej}},
  title         = {Release Early, Release Often, and Watch Your Users' Emotions: Lessons From Emotional Patterns},
  journal       = {IEEE Software},
  year          = {2019},
  volume        = {36},
  number        = {5},
  pages         = {32-37},
  month         = {Sep.},
  __markedentry = {[jacekdabrowski:2]},
  issn          = {1937-4194},
  keywords      = {emotion recognition;mobile computing;sentiment analysis;app stores;alternative apps;emotional patterns;sentiment analysis tools;app vendors;users emotions;Emotion recognition;Software tools;Software engineering;Sentiment analysis;Market research;Google;Computer applications},
}

@Article{8057860,
  author        = {S. {Scalabrino} and G. {Bavota} and B. {Russo} and M. D. {Penta} and R. {Oliveto}},
  title         = {Listening to the Crowd for the Release Planning of Mobile Apps},
  journal       = {IEEE Transactions on Software Engineering},
  year          = {2019},
  volume        = {45},
  number        = {1},
  pages         = {68-86},
  month         = {Jan},
  __markedentry = {[jacekdabrowski:2]},
  issn          = {2326-3881},
  keywords      = {data mining;Internet;mobile computing;pattern clustering;mobile app marketplaces;user reviews;CLAP;clustering reviews;crowd listener for release planning;Web application;categorizing reviews;Computer bugs;Planning;Tools;Google;Mobile communication;Security;Electronic mail;Release planning;mobile apps;mining software repositories},
}

@Article{7006337,
  author        = {H. {Khalid} and M. {Nagappan} and A. E. {Hassan}},
  title         = {Examining the Relationship between FindBugs Warnings and App Ratings},
  journal       = {IEEE Software},
  year          = {2016},
  volume        = {33},
  number        = {4},
  pages         = {34-39},
  month         = {July},
  __markedentry = {[jacekdabrowski:2]},
  issn          = {1937-4194},
  keywords      = {mobile computing;program diagnostics;FindBugs warnings;app ratings;mobile-app ecosystem;static-analysis warnings;free-to-download Android apps;warning categories;low-rated apps;user experience;static-analysis tools;Ecosystems;Androids;Humanoid robots;Computer bugs;Software development;Mobile communication;Computer applications;mobile apps;static analysis;user ratings;software quality assurance;FindBugs;Android;software engineering;software development},
}

@InProceedings{8952476,
  author        = {C. {Gao} and J. {Zeng} and X. {Xia} and D. {Lo} and M. R. {Lyu} and I. {King}},
  title         = {Automating App Review Response Generation},
  booktitle     = {2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)},
  year          = {2019},
  pages         = {163-175},
  month         = {Nov},
  __markedentry = {[jacekdabrowski:2]},
  issn          = {1938-4300},
  keywords      = {App reviews;response generation;neural machine translation},
}

@InProceedings{10.1145/2950290.2983938,
  author        = {Panichella, Sebastiano and Di Sorbo, Andrea and Guzman, Emitza and Visaggio, Corrado A. and Canfora, Gerardo and Gall, Harald C.},
  title         = {ARdoc: App Reviews Development Oriented Classifier},
  booktitle     = {Proceedings of the 2016 24th ACM SIGSOFT International Symposium on Foundations of Software Engineering},
  year          = {2016},
  series        = {FSE 2016},
  pages         = {1023–1027},
  address       = {New York, NY, USA},
  publisher     = {ACM},
  __markedentry = {[jacekdabrowski:2]},
  isbn          = {9781450342186},
  keywords      = {Sentiment Analysis, Natural Language Processing, User Reviews, Text classification, Mobile Applications},
  location      = {Seattle, WA, USA},
  numpages      = {5},
}

@InProceedings{8491133,
  author        = {V. T. {Dhinakaran} and R. {Pulle} and N. {Ajmeri} and P. K. {Murukannaiah}},
  title         = {App Review Analysis Via Active Learning: Reducing Supervision Effort without Compromising Classification Accuracy},
  booktitle     = {2018 IEEE 26th International Requirements Engineering Conference (RE)},
  year          = {2018},
  pages         = {170-181},
  month         = {Aug},
  __markedentry = {[jacekdabrowski:2]},
  issn          = {1090-705X},
  keywords      = {learning (artificial intelligence);mobile computing;pattern classification;automated app review analysis;requirements-related information;training dataset;machine learning paradigm;app review classification framework;active learning strategies;supervision effort;uncertainty sampling;rating;user experience;bugs;Training;Uncertainty;Labeling;Cloud computing;Task analysis;Computer bugs;Smart devices;app review analysis;active learning;mobile apps;Crowd RE;social requirements},
}

@Article{liang15,
  author        = {Liang, Ting-Peng and Li, Xin and Yang, Chin-Tsung and Wang, Mengyue},
  title         = {What in Consumer Reviews Affects the Sales of Mobile Apps: A Multifacet Sentiment Analysis Approach},
  journal       = {International Journal of Electronic Commerce},
  year          = {2015},
  volume        = {20},
  number        = {2},
  pages         = {236--260},
  __markedentry = {[jacekdabrowski:2]},
  publisher     = {Taylor \&amp; Francis},
}

@InProceedings{sorma13,
  author        = {Iacob, Claudia and Veerappa, Varsha and Harrison, Rachel},
  title         = {What Are You Complaining About?: A Study of Online Reviews of Mobile Applications},
  booktitle     = {Proceedings of the 27th International BCS Human Computer Interaction Conference},
  year          = {2013},
  pages         = {29:1--29:6},
  publisher     = {British Computer Society},
  __markedentry = {[jacekdabrowski:2]},
}

@InProceedings{cen14,
  author        = {Lei Cen and Luo Si and Ninghui Li and Hongxia Jin},
  title         = {User Comment Analysis for Android apps and CSPI Detection with Comment Expansion},
  booktitle     = {Proceeding of the 1st International Workshop on Privacy-Preserving IR (PIR)},
  year          = {2014},
  pages         = {25--30},
  __markedentry = {[jacekdabrowski:2]},
}

@Article{khalid15a,
  author        = {Khalid, Mubasher and Asif, Muhammad and Shehzaib, Usman},
  title         = {Towards Improving the Quality of Mobile App Reviews},
  journal       = {International Journal of Information Technology and Computer Science (IJITCS)},
  year          = {2015},
  volume        = {7},
  number        = {10},
  pages         = {35},
  __markedentry = {[jacekdabrowski:2]},
}

@InProceedings{ramafor13,
  author        = {Iacob, Claudia and Harrison, Rachel},
  title         = {Retrieving and Analyzing Mobile Apps Feature Requests from Online Reviews},
  booktitle     = {Proceedings of the 10th Working Conference on Mining Software Repositories},
  year          = {2013},
  pages         = {41--44},
  publisher     = {IEEE Press},
  __markedentry = {[jacekdabrowski:2]},
}

@InProceedings{iacob14,
  author        = {Claudia Iacob and Rachel Harrison and Shamal Faily},
  title         = {Online Reviews as First Class Artifacts in Mobile App Development},
  booktitle     = {Proceedings of the 5th International Conference on Mobile Computing, Applications, and Services. MobiCASE '13},
  year          = {2013},
  __markedentry = {[jacekdabrowski:2]},
}

@InProceedings{ouca13,
  author        = {Khalid, Hammad},
  title         = {On Identifying User Complaints of iOS Apps},
  booktitle     = {Proceedings of the 2013 International Conference on Software Engineering},
  year          = {2013},
  pages         = {1474--1476},
  publisher     = {IEEE Press},
  __markedentry = {[jacekdabrowski:2]},
}

@Article{mcilroy15b,
  author        = {McIlroy, Stuart and Shang, Weiyi and Ali, Nasir and Hassan, Ahmed},
  title         = {Is It Worth Responding to Reviews? A Case Study of the Top Free Apps in the Google Play Store},
  journal       = {IEEE Software},
  year          = {2015},
  volume        = {PP},
  __markedentry = {[jacekdabrowski:2]},
  publisher     = {IEEE},
}

@InProceedings{chandy12,
  author        = {Chandy, Rishi and Gu, Haijie},
  title         = {Identifying Spam in the iOS App Store},
  booktitle     = {Proceedings of the 2Nd Joint WICOW/AIRWeb Workshop on Web Quality},
  year          = {2012},
  pages         = {56--59},
  publisher     = {ACM},
  __markedentry = {[jacekdabrowski:2]},
}

@InProceedings{malavolta15a,
  author        = {Malavolta, Ivano and Ruberto, Stefano and Terragni, Valerio and Soru, Tommaso},
  title         = {Hybrid Mobile Apps in the Google Play Store: an Exploratory Investigation},
  booktitle     = {Proceedings of the 2nd ACM International Conference on Mobile Software Engineering and Systems},
  year          = {2015},
  publisher     = {ACM},
  __markedentry = {[jacekdabrowski:2]},
}

@InProceedings{malavolta15,
  author        = {Malavolta, Ivano and Ruberto, Stefano and Soru, Tommaso and Terragni, Valerio},
  title         = {End Users' Perception of Hybrid Mobile Apps in the Google Play Store},
  booktitle     = {Proceedings of the 4th International Conference on Mobile Services (MS)},
  year          = {2015},
  publisher     = {IEEE},
  __markedentry = {[jacekdabrowski:2]},
}

@InProceedings{ha13,
  author        = {Ha, Elizabeth and Wagner, Dietmar},
  title         = {Do Android users write about electric sheep? Examining consumer reviews in Google Play},
  booktitle     = {Consumer Communications and Networking Conference (CCNC), 2013 IEEE},
  year          = {2013},
  pages         = {149--157},
  __markedentry = {[jacekdabrowski:2]},
}

@InProceedings{gao15,
  author        = {Cuiyun Gao and Hui Xu and Junjie Hu and Yangfan Zhou},
  title         = {AR-Tracker: Track the Dynamics of Mobile Apps via User Review Mining},
  booktitle     = {2015 IEEE Symposium on Service-Oriented System Engineering, SOSE '15},
  year          = {2015},
  pages         = {284--290},
  __markedentry = {[jacekdabrowski:2]},
}

@InCollection{hoon15,
  author        = {Hoon, Leonard and Rodriguez-García, MiguelAngel and Vasa, Rajesh and Valencia-García, Rafael and Schneider, Jean-Guy},
  title         = {App Reviews: Breaking the User and Developer Language Barrier},
  booktitle     = {Trends and Applications in Software Engineering},
  publisher     = {Springer International Publishing},
  year          = {2016},
  volume        = {405},
  pages         = {223-233},
  __markedentry = {[jacekdabrowski:2]},
}

@InCollection{sun15,
  author        = {Sun, Dong and Peng, Rong},
  title         = {A Scenario Model Aggregation Approach for Mobile App Requirements Evolution Based on User Comments},
  booktitle     = {Requirements Engineering in the Big Data Era},
  publisher     = {Springer Berlin Heidelberg},
  year          = {2015},
  volume        = {558},
  pages         = {75-91},
  __markedentry = {[jacekdabrowski:2]},
}

@InProceedings{gomez15,
  author        = {Gomez, Maria and Rouvoy, Romain and Monperrus, Martin and Seinturier, Lionel},
  title         = {A Recommender System of Buggy App Checkers for App Store Moderators},
  booktitle     = {2nd ACM International Conference on Mobile Software Engineering and Systems},
  year          = {2015},
  publisher     = {IEEE},
  __markedentry = {[jacekdabrowski:2]},
}

@InProceedings{pavr12,
  author        = {Hoon, Leonard and Vasa, Rajesh and Schneider, Jean-Guy and Mouzakis, Kon},
  title         = {A Preliminary Analysis of Vocabulary in Mobile App User Reviews},
  booktitle     = {Proceedings of the 24th Australian Computer-Human Interaction Conference},
  year          = {2012},
  pages         = {245--248},
  publisher     = {ACM},
  __markedentry = {[jacekdabrowski:2]},
}

@InProceedings{pam12,
  author        = {Vasa, Rajesh and Hoon, Leonard and Mouzakis, Kon and Noguchi, Akihiro},
  title         = {A Preliminary Analysis of Mobile App User Reviews},
  booktitle     = {Proceedings of the 24th Australian Computer-Human Interaction Conference},
  year          = {2012},
  pages         = {241--244},
  publisher     = {ACM},
  __markedentry = {[jacekdabrowski:2]},
}

@Article{khalid15b,
  author        = {Khalid, Mubasher and Shehzaib, Usman and Asif, Muhammad},
  title         = {A Case of Mobile App Reviews as a Crowdsource},
  journal       = {International Journal of Information Engineering and Electronic Business (IJIEEB)},
  year          = {2015},
  volume        = {7},
  number        = {5},
  pages         = {39},
  __markedentry = {[jacekdabrowski:2]},
}

@InProceedings{10.1145/2915970.2916003,
  author        = {Keertipati, Swetha and Savarimuthu, Bastin Tony Roy and Licorish, Sherlock A.},
  title         = {Approaches for Prioritizing Feature Improvements Extracted from App Reviews},
  booktitle     = {Proceedings of the 20th International Conference on Evaluation and Assessment in Software Engineering},
  year          = {2016},
  series        = {EASE ’16},
  address       = {New York, NY, USA},
  publisher     = {ACM},
  __markedentry = {[jacekdabrowski:2]},
  articleno     = {Article 33},
  isbn          = {9781450336918},
  keywords      = {requirements elicitation, app reviews, crowdsourcing, prioritization},
  location      = {Limerick, Ireland},
  numpages      = {6},
}

@InProceedings{DBLP:conf/lrec/SangerLKAK16,
  author        = {S{\"a}nger, Mario and Leser, Ulf and Kemmerer, Steffen and Adolphs, Peter and Klinger, Roman},
  title         = {{SCARE} - The Sentiment Corpus of App Reviews with Fine-grained Annotations in {G}erman},
  booktitle     = {Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16)},
  year          = {2016},
  __markedentry = {[jacekdabrowski:2]},
}

@InProceedings{Shah2019SimulatingTI,
  author        = {Faiz Ali Shah and Kairit Sirts and Dietmar Pfahl},
  title         = {Simulating the Impact of Annotation Guidelines and Annotated Data on Extracting App Features from App Reviews},
  booktitle     = {International Conference on Software Technologies (ICSOFT)},
  year          = {2019},
  __markedentry = {[jacekdabrowski:2]},
}

@InProceedings{8449557,
  author        = {A. {Ciurumelea} and S. {Panichella} and H. C. {Gall}},
  title         = {Poster: Automated User Reviews Analyser},
  booktitle     = {2018 IEEE/ACM 40th International Conference on Software Engineering: Companion (ICSE-Companion)},
  year          = {2018},
  pages         = {317-318},
  month         = {May},
  __markedentry = {[jacekdabrowski:2]},
  issn          = {2574-1934},
  keywords      = {feedback;mobile computing;review sites;text analysis;direct feedback;valuable feedback;plan maintenance;evolution activities;unstructured textual nature;poster;automated user reviews analyser;AUREA;mobile app reviews classification;Tools;Software engineering;Feature extraction;Taxonomy;Smart phones;Software;Task analysis;Mobile Applications;User Reviews;Text Classification},
}

@InProceedings{7884612,
  author        = {A. {Ciurumelea} and A. {Schaufelbühl} and S. {Panichella} and H. C. {Gall}},
  title         = {Analyzing reviews and code of mobile apps for better release planning},
  booktitle     = {2017 IEEE 24th International Conference on Software Analysis, Evolution and Reengineering (SANER)},
  year          = {2017},
  pages         = {91-102},
  month         = {Feb},
  __markedentry = {[jacekdabrowski:2]},
  issn          = {null},
  keywords      = {information retrieval;learning (artificial intelligence);mobile computing;program debugging;software development management;software maintenance;source code (software);release planning;mobile applications industry;bug fixing;user feedback;mobile specific categories;maintenance activities;evolution activities;user request referencer prototype;URR;machine learning;information retrieval techniques;source code files;Taxonomy;Mobile communication;Mobile applications;Computer bugs;Prototypes;Batteries;Maintenance engineering;Mobile Applications;User Reviews;Text Classification;Code Localization},
}

@InProceedings{8048893,
  author        = {E. C. {Groen} and S. {Kopczyńska} and M. P. {Hauer} and T. D. {Krafft} and J. {Doerr}},
  title         = {Users — The Hidden Software Product Quality Experts?: A Study on How App Users Report Quality Aspects in Online Reviews},
  booktitle     = {2017 IEEE 25th International Requirements Engineering Conference (RE)},
  year          = {2017},
  pages         = {80-89},
  month         = {Sep.},
  __markedentry = {[jacekdabrowski:2]},
  issn          = {2332-6441},
  keywords      = {Big Data;fault tolerance;feedback;open systems;software quality;software reliability;user interfaces;hidden software product quality experts;online reviews;user feedback;usability;reliability;operability;adaptability;fault tolerance;interoperability;language patterns;Big Data;Tagging;Usability;Reliability;Quality assessment;Product design;Google;crowd based requirements engineering;requirements engineering;non-functional requirements;online user reviews;quality characteristics;quality requirements},
}

@InProceedings{8330198,
  author        = {G. {Grano} and A. {Ciurumelea} and S. {Panichella} and F. {Palomba} and H. C. {Gall}},
  title         = {Exploring the integration of user feedback in automated testing of Android applications},
  booktitle     = {2018 IEEE 25th International Conference on Software Analysis, Evolution and Reengineering (SANER)},
  year          = {2018},
  pages         = {72-83},
  month         = {March},
  __markedentry = {[jacekdabrowski:2]},
  issn          = {null},
  keywords      = {Android (operating system);mobile computing;program debugging;program testing;software quality;complementary user feedback;automated testing tools;high-quality mobile apps;mobile application testing;Android applications;crash bug detection;Testing;Tools;Computer bugs;Androids;Humanoid robots;Mobile applications;Automated Software Testing;Mobile Applications;User Reviews Analysis},
}

@Article{10.1145/3141771,
  author        = {Mcilroy, Stuart and Shang, Weiyi and Ali, Nasir and Hassan, Ahmed E.},
  title         = {User Reviews of Top Mobile Apps in Apple and Google App Stores},
  journal       = {Commun. ACM},
  year          = {2017},
  volume        = {60},
  number        = {11},
  pages         = {62–67},
  month         = oct,
  __markedentry = {[jacekdabrowski:2]},
  address       = {New York, NY, USA},
  issn          = {0001-0782},
  issue_date    = {October 2017},
  numpages      = {6},
  publisher     = {ACM},
}

@InProceedings{7381797,
  author        = {C. {Gao} and B. {Wang} and P. {He} and J. {Zhu} and Y. {Zhou} and M. R. {Lyu}},
  title         = {PAID: Prioritizing app issues for developers by tracking user reviews over versions},
  booktitle     = {2015 IEEE 26th International Symposium on Software Reliability Engineering (ISSRE)},
  year          = {2015},
  pages         = {35-45},
  month         = {Nov},
  __markedentry = {[jacekdabrowski:2]},
  issn          = {null},
  keywords      = {data mining;mobile computing;program debugging;user interfaces;bug-fixing;version-modification process;user review mining;user interface;privacy leakage;prioritizing application issue-for-developer;PAID design;ThemeRiver;mobile application;Data mining;Labeling;Filter banks;Computer science;Manuals;Mobile communication;Market research},
}

@Article{8606261,
  author        = {A. {AlSubaihin} and F. {Sarro} and S. {Black} and L. {Capra} and M. {Harman}},
  title         = {App Store Effects on Software Engineering Practices},
  journal       = {IEEE Transactions on Software Engineering},
  year          = {2019},
  pages         = {1-1},
  __markedentry = {[jacekdabrowski:2]},
  issn          = {2326-3881},
  keywords      = {Software engineering;Software;Interviews;Data mining;Testing;Data collection;Business;Empirical Software Engineering;Mobile App Development;App Store Analysis},
}

@InProceedings{8587288,
  author        = {G. {Greenheld} and B. T. R. {Savarimuthu} and S. A. {Licorish}},
  title         = {Automating Developers' Responses to App Reviews},
  booktitle     = {2018 25th Australasian Software Engineering Conference (ASWEC)},
  year          = {2018},
  pages         = {66-70},
  month         = {Nov},
  __markedentry = {[jacekdabrowski:2]},
  issn          = {1530-0803},
  keywords      = {formal specification;information retrieval;Internet;mobile computing;user interfaces;software systems;app reviews;app ratings;user reviews;socially-acceptable responses;automating developers;Google Play response system;Google Play de facto review response system;Google;Task analysis;User interfaces;Information retrieval;Information science;Atmospheric measurements;Particle measurements;app review;response recommendation;social norms;user interface design;information retrieval},
}

@InProceedings{10.4108/eai.30-11-2016.2266941,
  author        = {Iacob, Claudia and Faily, Shamal and Harrison, Rachel},
  title         = {MARAM: Tool Support for Mobile App Review Management},
  booktitle     = {Proceedings of the 8th EAI International Conference on Mobile Computing, Applications and Services},
  year          = {2016},
  series        = {MobiCASE’16},
  pages         = {42–50},
  publisher     = {ICST (Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering)},
  __markedentry = {[jacekdabrowski:2]},
  numpages      = {9},
}

@InProceedings{8491124,
  author        = {G. {Williams} and A. {Mahmoud}},
  title         = {Modeling User Concerns in the App Store: A Case Study on the Rise and Fall of Yik Yak},
  booktitle     = {2018 IEEE 26th International Requirements Engineering Conference (RE)},
  year          = {2018},
  pages         = {64-75},
  month         = {Aug},
  __markedentry = {[jacekdabrowski:2]},
  issn          = {1090-705X},
  keywords      = {data privacy;marketing;mobile computing;social networking (online);market components;mobile app ecosystem;Yik Yak;design decisions;rival apps;anonymous social networking apps;app developers;sustainable release engineering strategies;market viability;modeling user concerns;mobile application stores;market entry;accelerated pace;unprecedented pace;mobile software production;highly competitive market;vibrant market;engineering decisions;complex interplay;app market entry;systematic in-depth analysis;core features;Software;Twitter;Companies;History;Message systems;Requirements modeling;app store analysis;domain engineering;case study},
}

@InProceedings{8534785,
  author        = {A. {Puspaningrum} and D. {Siahaan} and C. {Fatichah}},
  title         = {Mobile App Review Labeling Using LDA Similarity and Term Frequency-Inverse Cluster Frequency (TF-ICF)},
  booktitle     = {2018 10th International Conference on Information Technology and Electrical Engineering (ICITEE)},
  year          = {2018},
  pages         = {365-370},
  month         = {July},
  __markedentry = {[jacekdabrowski:2]},
  issn          = {null},
  keywords      = {data mining;mobile computing;pattern classification;pattern clustering;software maintenance;map hidden topics;calculating term similarity value;hidden topic;pre-defined signifier term list;LDAS TF-ICF;mobile app review labeling;user review mining;innovative models;technical recommendation;software developers;software maintenance;software evolution;user review categorization;classification methods;topic modelling method;term frequency-inverse cluster frequency;term frequency-inverse corpus frequency;Computer bugs;Labeling;Software;Information technology;Electrical engineering;Resource management;Mathematical model;LDA;Review Semantic Similarity;Software Evolution;Software Maintenance;TF-ICF},
}

@InProceedings{8719458,
  author        = {T. {Wang} and P. {Liang} and M. {Lu}},
  title         = {What Aspects Do Non-Functional Requirements in App User Reviews Describe? An Exploratory and Comparative Study},
  booktitle     = {2018 25th Asia-Pacific Software Engineering Conference (APSEC)},
  year          = {2018},
  pages         = {494-503},
  month         = {Dec},
  __markedentry = {[jacekdabrowski:2]},
  issn          = {1530-1362},
  keywords      = {data mining;formal specification;mobile computing;software quality;user requirements;comparative study;industrial requirements specifications;nonfunctional requirements;NFR;interface behavior;user review sentences;app user reviews;iBooks;WhatsApp;Usability;Software quality;IEC Standards;ISO Standards;Reliability;Computer architecture;Crowd -based Requirements Engineering;App User Reviews;Classification of NFRs;Comparative Study},
}

@InProceedings{8054850,
  author        = {E. {Bakiu} and E. {Guzman}},
  title         = {Which Feature is Unusable? Detecting Usability and User Experience Issues from User Reviews},
  booktitle     = {2017 IEEE 25th International Requirements Engineering Conference Workshops (REW)},
  year          = {2017},
  pages         = {182-187},
  month         = {Sep.},
  __markedentry = {[jacekdabrowski:2]},
  issn          = {null},
  keywords      = {feature extraction;human factors;learning (artificial intelligence);sentiment analysis;software quality;software users;software features;user reviews;software application;user experience issues;software quality;Usability and user experience;UUX;collocation algorithm;feature extraction;lexical sentiment analysis;machine learning;Feature extraction;Usability;Data mining;Visualization;Software algorithms;Sentiment analysis;user feedback;software evolution;text mining;user experience;usability},
}

@InProceedings{DBLP:conf/icsoc/Xiao19,
  author        = {Jianmao Xiao},
  title         = {OSPAci: Online Sentiment-Preference Analysis of User Reviews for Continues App Improvement},
  booktitle     = {Service-Oriented Computing - {ICSOC} 2019 Workshops - WESOACS, ASOCA, ISYCC, TBCE, and STRAPS, Toulouse, France, October 28-31, 2019, Revised Selected Papers},
  year          = {2019},
  editor        = {Sami Yangui and Athman Bouguettaya and Xiao Xue and Noura Faci and Walid Gaaloul and Qi Yu and Zhangbing Zhou and Nathalie Hernandez and Elisa Yumi Nakagawa},
  volume        = {12019},
  series        = {Lecture Notes in Computer Science},
  pages         = {273--279},
  publisher     = {Springer},
  __markedentry = {[jacekdabrowski:2]},
  bibsource     = {dblp computer science bibliography, https://dblp.org},
  biburl        = {https://dblp.org/rec/conf/icsoc/Xiao19.bib},
  doi           = {10.1007/978-3-030-45989-5\_23},
  timestamp     = {Fri, 09 Apr 2021 18:46:48 +0200},
  url           = {https://doi.org/10.1007/978-3-030-45989-5\_23},
}

@InProceedings{10.1145/3377815.3381382,
  author        = {Shams, Rifat Ara and Hussain, Waqar and Oliver, Gillian and Nurwidyantoro, Arif and Perera, Harsha and Whittle, Jon},
  title         = {Society-Oriented Applications Development: Investigating Users' Values from Bangladeshi Agriculture Mobile Applications},
  booktitle     = {Proceedings of the ACM/IEEE 42nd International Conference on Software Engineering: Software Engineering in Society},
  year          = {2020},
  series        = {ICSE-SEIS '20},
  pages         = {53–62},
  address       = {New York, NY, USA},
  publisher     = {Association for Computing Machinery},
  __markedentry = {[jacekdabrowski:2]},
  abstract      = {Limited consideration of users' values in mobile applications (apps) can lead to user disappointments and negative socio-economic consequences. Therefore, it is important to consider values in app development to avoid such adverse effects and to secure the optimum use of apps. With this aim, we conducted a case study to identify the users' desired values that are either reflected or missing in the existing Bangladeshi agriculture mobile apps. We manually analyzed 1522 reviews from 29 existing Bangladeshi agriculture apps in Google Play by following a widely used human values theory, Schwartz's theory of basic human values. Our results show that users of the selected apps have twenty one (21) desired individual values where eleven (11) values are reflected in the apps and ten (10) values are missing. This research provides a basis for the developers to design apps that consider users' values. It also provides a direction on which values they should address while developing apps. Moreover, repeating this research in different domains or societies would result in society-oriented apps that are more sensitive to users' values.},
  doi           = {10.1145/3377815.3381382},
  isbn          = {9781450371244},
  keywords      = {mobile apps, human values, society-oriented applications development, review analysis},
  location      = {Seoul, South Korea},
  numpages      = {10},
  url           = {https://doi.org/10.1145/3377815.3381382},
}

@InProceedings{10.1145/3382494.3410686,
  author        = {Srisopha, Kamonphop and Link, Daniel and Swami, Devendra and Boehm, Barry},
  title         = {Learning Features That Predict Developer Responses for IOS App Store Reviews},
  booktitle     = {Proceedings of the 14th ACM / IEEE International Symposium on Empirical Software Engineering and Measurement (ESEM)},
  year          = {2020},
  series        = {ESEM '20},
  address       = {New York, NY, USA},
  publisher     = {Association for Computing Machinery},
  __markedentry = {[jacekdabrowski:2]},
  abstract      = {Background: Which aspects of an iOS App Store user review motivate developers to respond? Numerous studies have been conducted to extract useful information from reviews, but limited effort has been expended to answer this question.Aims: This work aims to investigate the potential of using a machine learning algorithm and the features that can be extracted from user reviews to model developers' response behavior. Through this process, we want to uncover the learned relationship between these features and developer responses.Method: For our prediction, we run a random forest algorithm over the derived features. We then perform a feature importance analysis to understand the relative importance of each individual feature and groups thereof.Results: Through a case study of eight popular apps, we show patterns in developers' response behavior. Our results demonstrate not only that rating and review length are among the most important but also that review posted time, sentiment, and the writing style play an important role in the response prediction. Additionally, the variation in feature importance ranking implies that different app developers use different feature weights when prioritizing responses.Conclusions: Our results may provide guidance for those building review or response prioritization tools and developers wishing to prioritize their responses effectively.},
  articleno     = {12},
  doi           = {10.1145/3382494.3410686},
  isbn          = {9781450375801},
  keywords      = {Feature Importance, User Reviews, App Store Mining, Prioritization, Developer Response, Random Forest},
  location      = {Bari, Italy},
  numpages      = {11},
  url           = {https://doi.org/10.1145/3382494.3410686},
}

@InProceedings{10.1145/3383219.3383258,
  author        = {Srisopha, Kamonphop and Swami, Devendra and Link, Daniel and Boehm, Barry},
  title         = {How Features in IOS App Store Reviews Can Predict Developer Responses},
  booktitle     = {Proceedings of the Evaluation and Assessment in Software Engineering},
  year          = {2020},
  series        = {EASE '20},
  pages         = {336–341},
  address       = {New York, NY, USA},
  publisher     = {Association for Computing Machinery},
  __markedentry = {[jacekdabrowski:2]},
  abstract      = {Until recently, communications regarding apps on the iOS App Store have been one-way from users to developers, with developers unable to respond to reviews directly. While studies have shown that responding to reviews improves an app's overall rating and user satisfaction, resource limitations make it so developers can usually only respond to some of the reviews. Although developers' response behavior has been studied, little is known about which features (aspects) of user reviews spur their responses. Motivated by these observations, we investigate a wide range of features that can be extracted from a user review and apply a random forest algorithm and the features it extracts to predict whether developers will respond to that review. We then determine the importance of these features in distinguishing reviews that receive a developer response from those that do not. Through a case study of three popular free-to-download iOS apps, we find that although features such as rating and review length are among the most important features for all apps, each app has its own individual feature importance ranking, indicating that developers assign different feature weights when prioritizing reviews. Our results may help guide research or the development of tools that are more in line with developers' actual response behavior.},
  doi           = {10.1145/3383219.3383258},
  isbn          = {9781450377317},
  keywords      = {Prioritization, User Reviews, Feature Selection, Developer Response, Text Mining, Feature Importance, App Store Mining},
  location      = {Trondheim, Norway},
  numpages      = {6},
  url           = {https://doi.org/10.1145/3383219.3383258},
}

@InProceedings{10.1145/3387940.3391492,
  author        = {Srisopha, Kamonphop and Phonsom, Chukiat and Li, Mingzhe and Link, Daniel and Boehm, Barry},
  title         = {On Building an Automatic Identification of Country-Specific Feature Requests in Mobile App Reviews: Possibilities and Challenges},
  booktitle     = {Proceedings of the IEEE/ACM 42nd International Conference on Software Engineering Workshops},
  year          = {2020},
  series        = {ICSEW'20},
  pages         = {494–498},
  address       = {New York, NY, USA},
  publisher     = {Association for Computing Machinery},
  __markedentry = {[jacekdabrowski:2]},
  abstract      = {Mobile app stores are available in over 150 countries, allowing users from all over the world to leave public reviews of downloaded apps. Previous studies have shown that such reviews can serve as sources of requirements and suggested that users from different countries have different needs and expectations regarding the same app. However, the tremendous quantity of reviews from multiple countries, as well as several other factors, complicates identifying country-specific app feature requests. In this work, we present a simple approach to address this through NLP-based analysis and discuss some of the challenges involved in using the NLP-based analysis for this task.},
  doi           = {10.1145/3387940.3391492},
  isbn          = {9781450379632},
  keywords      = {Requirements Engineering, Text Analysis, Software Evolution, Cross-Country Analysis, User Review Analysis},
  location      = {Seoul, Republic of Korea},
  numpages      = {5},
  url           = {https://doi.org/10.1145/3387940.3391492},
}

@InProceedings{10.1145/3417113.3422186,
  author        = {Wang, Huiyi and Wang, Liu and Wang, Haoyu},
  title         = {Market-Level Analysis of Government-Backed COVID-19 Contact Tracing Apps},
  booktitle     = {Proceedings of the 35th IEEE/ACM International Conference on Automated Software Engineering Workshops},
  year          = {2020},
  series        = {ASE '20},
  pages         = {79–84},
  address       = {New York, NY, USA},
  publisher     = {Association for Computing Machinery},
  __markedentry = {[jacekdabrowski:2]},
  abstract      = {To help curb the spread of the COVID-19 pandemic, governments and public health authorities around the world have launched a number of contact-tracing apps. Although contact tracing apps have received extensive attentions from the research community, no existing work has characterized the users' adoption of contact tracing apps from the app market level. In this work, we perform the first market-level analysis of contact tracing apps. We perform a longitudinal empirical study (over 4 months) of eight government-backed COVID-19 contact tracing apps in iOS app store. We first collect all the daily meta information (e.g., app updates, app rating, app comments, etc.) of these contact tracing apps from their launch to 2020-07-31. Then we characterize them from release practice, app popularity, and mobile users' feedback. Our study reveals various issues related to contact tracing apps from the users' perspective, hoping to help improve the quality of contact tracing apps and thus achieving a high level of adoption in the population.},
  doi           = {10.1145/3417113.3422186},
  isbn          = {9781450381284},
  location      = {Virtual Event, Australia},
  numpages      = {6},
  url           = {https://doi.org/10.1145/3417113.3422186},
}

@InProceedings{10.1145/3380625.3380665,
  author        = {Wang, Ying and Zheng, Liwei and Li, Ning},
  title         = {ROM: A Requirement Opinions Mining Method Preliminary Try Based on Software Review Data},
  booktitle     = {Proceedings of the 2020 4th International Conference on Management Engineering, Software Engineering and Service Sciences},
  year          = {2020},
  series        = {ICMSS 2020},
  pages         = {26–33},
  address       = {New York, NY, USA},
  publisher     = {Association for Computing Machinery},
  __markedentry = {[jacekdabrowski:2]},
  abstract      = {Requirement opinion mining aims to mine user opinions that can be used to help the mining of software requirements from various data sources. However, in the development of social network systems, software application platforms or stores and other data sources, the massive, noisy, non-standard data, makes the mining of effective requirement opinions more difficult. Therefore, there is less work in software requirements mining based on the data of software review in development social media or application market. This paper attempts to provide some knowledge support for requirement user story establishing in RE based on the opinion mining and clustering of massively software review data. First of all, this paper combines the requirements of the requirements engineering field to define the requirement opinions, functional requirement opinions and non-functional requirements opinions. Secondly, using the deep learning model to classify the functional requirement reviews and non-functional requirements reviews included in the reviews; Based on the differences between functional data and non-functional data, this paper defines three categories in the description of software functional data, and chooses to use sequence labeling methods to identify functional requirements. Then use the K-means clustering method based on word vector to cluster the review data, and combine TF-IDF and syntactic analysis to extract the aspect and aspect requirements or specific requirements of the requirement opinion respectively, so as to realize the requirement opinion mining of software review data. Finally, this article will give a case study based on the user review data of the mobile phone application service platform 360 mobile assistants.},
  doi           = {10.1145/3380625.3380665},
  isbn          = {9781450376419},
  keywords      = {clustering, Review data, requirement opinion mining},
  location      = {Wuhan, China},
  numpages      = {8},
  url           = {https://doi.org/10.1145/3380625.3380665},
}

@Article{10.1145/3409585,
  author        = {Franzmann, Daniel and Eichner, Arvid and Holten, Roland},
  title         = {How Mobile App Design Overhauls Can Be Disastrous in Terms of User Perception: The Case of Snapchat},
  journal       = {Trans. Soc. Comput.},
  year          = {2020},
  volume        = {3},
  number        = {4},
  month         = sep,
  __markedentry = {[jacekdabrowski:2]},
  abstract      = {Smartphone apps are regularly updated and enhanced. However, design overhauls—that change the whole look of an app—are not expected to impact a user's behavior and, more specifically, continuance intentions. We reevaluate this claim based on the overwhelmingly negative feedback the social multimedia messaging app Snapchat received following a design overhaul released in February 2018. Following a mixed-method approach, we first analyze Snapchat's app ratings and their significant drop after the release of the update, using a Chow-test. Second, we use text mining to analyze a data set of 737,182 text reviews from the Google Play Store. We thereby provide empirical evidence that a design overhaul led to a significant decrease in app store ratings and started a social media firestorm among its users. Third, to theoretically explain the causes of the decrease in ratings, we conducted interviews with 26 Snapchat users. We contribute to the current discussion in IS research debates concerning whether perceived ease of use does play an essential role in the post-adoption context: We find evidence that substantial changes in an app design triggers a new adoption process and impacts the perceived ease of use, and thus, in particular, we contribute to the theoretical understanding of how users perceive design overhauls.},
  address       = {New York, NY, USA},
  articleno     = {18},
  doi           = {10.1145/3409585},
  issn          = {2469-7818},
  issue_date    = {October 2020},
  keywords      = {post-adoption, software updates, Design overhauls, perceived ease of use},
  numpages      = {21},
  publisher     = {Association for Computing Machinery},
  url           = {https://doi.org/10.1145/3409585},
}

@InProceedings{9357270,
  author        = {Gunaratnam, Inthuja and Wickramarachchi, D.N.},
  title         = {Computational Model for Rating Mobile Applications based on Feature Extraction},
  booktitle     = {2020 2nd International Conference on Advancements in Computing (ICAC)},
  year          = {2020},
  volume        = {1},
  pages         = {180-185},
  month         = {Dec},
  __markedentry = {[jacekdabrowski:2]},
  abstract      = {Google Play Store and App Store allow users to share their opinions and helps to measure users satisfaction level about the app through user comments. However, it's highly time-consuming to process all reviews manually. The usefulness of star ratings is limited for development teams since a rating represents an average of both positive and negative evaluations. Therefore, an automated solution is needed to systematically analyze reviews and other textual forms of data. The main objective of this research is to build a platform that rate apps by feature extraction and sentiment analysis to calculate the functionality index of apps based on metrics obtained by surveying 204 mobile phone users. The 5 topmost metrics obtained from them among the 16 metrics obtained from the literature review are usability, price, and frequency of updates, ad-freeness and battery consuming level. This research focuses on selected apps in music and audio category. To perform app rating indexes calculation of the overall app's reviews; data extraction, data cleaning, POS tagging, feature extraction, feature/feature values pairing, weighted feature rating, overall apps' rating and feature-wise app rating is done on textual data. The accuracy of the created model is measured by the level of satisfaction from users.},
  doi           = {10.1109/ICAC51239.2020.9357270},
  keywords      = {Measurement;Sentiment analysis;Computational modeling;Tagging;Feature extraction;Usability;Optimization;Sentiment Analysis;Feature Extraction;Review Analysis;Mobile Apps;Apps Optimization},
}

@Article{8961125,
  author        = {Zhou, Yu and Su, Yanqi and Chen, Taolue and Huang, Zhiqiu and Gall, Harald C. and Panichella, Sebastiano},
  title         = {User Review-Based Change File Localization for Mobile Applications},
  journal       = {IEEE Transactions on Software Engineering},
  year          = {2020},
  pages         = {1-1},
  __markedentry = {[jacekdabrowski:2]},
  abstract      = {In the current mobile app development, novel and emerging DevOps practices (e.g., Continuous Delivery, Integration, and user feedback analysis) and tools are becoming more widespread. For instance, the integration of user feedback (provided in the form of user reviews) in the software release cycle represents a valuable asset for the maintenance and evolution of mobile apps. To fully make use of these assets, it is highly desirable for developers to establish semantic links between the user reviews and the software artefacts to be changed (e.g., source code and documentation), and thus to localize the potential files to change for addressing the user feedback. In this paper, we propose RISING (Reviews Integration via claSsification, clusterIng, and linkiNG), an automated approach to support the continuous integration of user feedback via classification, clustering, and linking of user reviews. RISING leverages domain-specific constraint information and semi-supervised learning to group user reviews into multiple fine-grained clusters concerning similar users' requests. Then, by combining the textual information from both commit messages and source code, it automatically localizes potential change files to accommodate the users' requests. Our empirical studies demonstrate that the proposed approach outperforms the state-of-the-art baseline work in terms of clustering and localization accuracy, and thus produces more reliable results.},
  doi           = {10.1109/TSE.2020.2967383},
  issn          = {1939-3520},
  keywords      = {Software;Mobile applications;Testing;Tools;Maintenance engineering;Reliability;Software engineering;User review;Mobile apps;Information retrieval;Change File Localization},
}

@InProceedings{9283933,
  author        = {Guo, Hui and Singh, Munindar P.},
  title         = {Caspar: Extracting and Synthesizing User Stories of Problems from App Reviews},
  booktitle     = {2020 IEEE/ACM 42nd International Conference on Software Engineering (ICSE)},
  year          = {2020},
  pages         = {628-640},
  month         = {Oct},
  __markedentry = {[jacekdabrowski:2]},
  abstract      = {A user's review of an app often describes the user's interactions with the app. These interactions, which we interpret as mini stories, are prominent in reviews with negative ratings. In general, a story in an app review would contain at least two types of events: user actions and associated app behaviors. Being able to identify such stories would enable an app's developer in better maintaining and improving the app's functionality and enhancing user experience. We present Caspar, a method for extracting and synthesizing user-reported mini stories regarding app problems from reviews. By extending and applying natural language processing techniques, Caspar extracts ordered events from app reviews, classifies them as user actions or app problems, and synthesizes action-problem pairs. Our evaluation shows that Caspar is effective in finding action-problem pairs from reviews. First, Caspar classifies the events with an accuracy of 82.0% on manually labeled data. Second, relative to human evaluators, Caspar extracts event pairs with 92.9% precision and 34.2% recall. In addition, we train an inference model on the extracted action-problem pairs that automatically predicts possible app problems for different use cases. Preliminary evaluation shows that our method yields promising results. Caspar illustrates the potential for a deeper understanding of app reviews and possibly other natural language artifacts arising in software engineering.},
  issn          = {1558-1225},
  keywords      = {Predictive models;Natural language processing;Software engineering;natural language processing;app review analysis;event extraction;event inference;requirements},
}

@InProceedings{9276612,
  author        = {Li, Shuyue and Guo, Jiaqi and Fan, Ming and Lou, Jian-Guang and Zheng, Qinghua and Liu, Ting},
  title         = {Automated Bug Reproduction from User Reviews for Android Applications},
  booktitle     = {2020 IEEE/ACM 42nd International Conference on Software Engineering: Software Engineering in Practice (ICSE-SEIP)},
  year          = {2020},
  pages         = {51-60},
  month         = {Oct},
  __markedentry = {[jacekdabrowski:2]},
  abstract      = {Bug-related user reviews of mobile applications have negative influence on their reputation and competence, and thus these reviews are highly regarded by developers. Before bug fixing, developers need to manually reproduce the bugs reported in user reviews, which is an extremely time-consuming and tedious task. Hence, it is highly expected to automate this process. However, it is challenging to do so since user reviews are hard to understand and poorly informative for bug reproduction (especially lack of reproduction steps). In this paper, we propose RepRev to automatically Reproduce Android application bugs from user Reviews. Specifically, RepRev leverages natural language processing techniques to extract valuable information for bug reproduction. Then, it ranks GUI components by semantic similarity with the user review and dynamically searches on apps with a novel one-step exploration technique. To evaluate RepRev, we construct a benchmark including 63 crash-related user reviews from Google Play, which have been reproduced successfully by three graduate students. On this benchmark, RepRev presents comparable performance with humans, which successfully reproduces 44 user reviews in our benchmark (about 70%) with 432.2 seconds average time. We make the implementation of our approach publicly available, along with the artifacts and experimental data we used [4].},
  keywords      = {Computer bugs;Graphical user interfaces;Benchmark testing;Internet;Data mining;Task analysis;Software engineering;Bug Reproduction;Android Applications;User Review Analysis},
}

@InProceedings{9270313,
  author        = {Yadav, Aman and Fard, Fatemeh H.},
  title         = {Semantic Analysis of Issues on Google Play and Twitter},
  booktitle     = {2020 IEEE/ACM 42nd International Conference on Software Engineering: Companion Proceedings (ICSE-Companion)},
  year          = {2020},
  pages         = {308-309},
  month         = {Oct},
  __markedentry = {[jacekdabrowski:2]},
  abstract      = {Mobile app users post their opinion about the apps, report bugs or request features on various platforms, the main one being App Stores. Previous research suggests that Twitter should be used as an additional resource to receive users' feedback, as app users tweet different issues. Although the classification and review summarization methods are developed previously for each platform separately, manual investigation of reviews or tweets is still required to identify the similar or different points that are discussed on App Store or Twitter. In this paper, we propose a framework to study the differences or similarities among app reviews from Google Play Store and tweets automatically by using the semantics of the words. The results from several experiments compared with expert evaluation, confirm that it can be applied to identify the similarities or differences among the extracted topics, n-grams, and users' comments.},
  issn          = {2574-1926},
  keywords      = {Social networking (online);Computer bugs;Blogs;Semantics;Internet;Software;Mobile applications;app review analysis;Twitter;bug reports;semantic analysis},
}

@InProceedings{9359287,
  author        = {Song, Rui and Li, Tong and Ding, Zhiming},
  title         = {Automatically Identifying Requirements-Oriented Reviews Using a Top-Down Feature Extraction Approach},
  booktitle     = {2020 27th Asia-Pacific Software Engineering Conference (APSEC)},
  year          = {2020},
  pages         = {450-454},
  month         = {Dec},
  __markedentry = {[jacekdabrowski:2]},
  abstract      = {Processing application user reviews has recently been recognized as an efficient approach to explore user requirements. However, most existing approaches focus on mining the reviews themselves without effectively associating the reviews with requirements concepts, limiting the effectiveness of review mining for requirements analysis tasks. In this paper, we propose to automatically identify Requirements-oriented Reviews (RoRs) from software application reviews by considering requirements specific domain knowledge and syntactic information of user reviews. Specifically, we first define a conceptual model of RoRs based on existing requirements ontology and user review categories, establishing connections between the concepts of requirements engineering and user reviews. We then systematically identify the textual features of RoRs by following a conceptual model-driven top-down strategy. Based on such features, we then train effective RoR classifiers to identify RoRs. To evaluate the performance of our approach, we have applied our approach to a real dataset of mobile application reviews, the results of which show that our approach can effectively identify RoRs with an F-measure of 0.8, outperforming than the baselines.},
  doi           = {10.1109/APSEC51365.2020.00054},
  issn          = {2640-0715},
  keywords      = {Syntactics;Feature extraction;Software;Data mining;Requirements engineering;Task analysis;Software engineering;requirements-oriented reviews;textual features;conceptual model;classification},
}

@InProceedings{9240699,
  author        = {Hadi, Mohammad Abdul and Fard, Fatemeh H},
  title         = {AOBTM: Adaptive Online Biterm Topic Modeling for Version Sensitive Short-texts Analysis},
  booktitle     = {2020 IEEE International Conference on Software Maintenance and Evolution (ICSME)},
  year          = {2020},
  pages         = {593-604},
  month         = {Sep.},
  __markedentry = {[jacekdabrowski:2]},
  abstract      = {Analysis of mobile app reviews has shown its important role in requirement engineering, software maintenance and evolution of mobile apps. Mobile app developers check their users' reviews frequently to clarify the issues experienced by users or capture the new issues that are introduced due to a recent app update. App reviews have a dynamic nature and their discussed topics change over time. The changes in the topics among collected reviews for different versions of an app can reveal important issues about the app update. A main technique in this analysis is using topic modeling algorithms. However, app reviews are short texts and it is challenging to unveil their latent topics over time. Conventional topic models such as Latent Dirichlet Allocation (LDA) and Probabilistic Latent Semantic Analysis (PLSA) suffer from the sparsity of word co-occurrence patterns while inferring topics for short texts. Furthermore, these algorithms cannot capture topics over numerous consecutive time-slices (or versions). Online topic modeling algorithms such as Online LDA (OLDA) and Online Biterm Topic Model (OBTM) speed up the inference of topic models for the texts collected in the latest time-slice by saving a fraction of data from the previous time-slice. But these algorithms do not analyze the statistical-data of all the previous time-slices, which can confer contributions to the topic distribution of the current time-slice.In this paper, we propose Adaptive Online Biterm Topic Model (AOBTM) to model topics in short texts adaptively. AOBTM alleviates the sparsity problem in short-texts and considers the statistical-data for an optimal number of previous time-slices. We also propose parallel algorithms to automatically determine the optimal number of topics and the best number of previous versions that should be considered in topic inference phase. Automatic evaluation on collections of app reviews and real-world short text datasets confirm that AOBTM can find more coherent topics and outperforms the state-of-the-art baselines. For reproducibility of the results, we open source all scripts.},
  doi           = {10.1109/ICSME46990.2020.00062},
  issn          = {2576-3148},
  keywords      = {Analytical models;Adaptation models;Software maintenance;Software algorithms;Inference algorithms;Data models;Mobile applications;App review analysis;adaptive topic model;biterm;online algorithm;automatic parameter setting},
}

@Article{TAO2020106290,
  author        = {Chuanqi Tao and Hongjing Guo and Zhiqiu Huang},
  title         = {Identifying security issues for mobile applications based on user review summarization},
  journal       = {Information and Software Technology},
  year          = {2020},
  volume        = {122},
  pages         = {106290},
  __markedentry = {[jacekdabrowski:2]},
  abstract      = {Context
With the development of mobile apps, public concerns about security issues are continually rising. From the user’s perspective, it is crucial to be aware of the security issues of apps. Reviews serve as an important channel for users to discover the diverse issues of apps. However, previous works rarely rely on existing reviews to provide a detailed summarization of the app’s security issues.
Objective
To provide a detailed overview of apps’ security issues for users, this paper introduces SRR-Miner, a novel review summarization approach that automatically summarizes security issues and users’ sentiments.
Method
SRR-Miner follows a keyword-based approach to extracting security-related review sentences. It summarizes security issues and users’ sentiments with  <misbehavior-aspect-opinion>  triples, which makes full use of the deep analysis of sentence structures. SRR-Miner also provides visualized review summarization through a radar chart.
Results
The evaluation on 17 mobile apps shows that SRR-Miner achieves higher F1-score and MCC than Machine Learning-based classification approaches in extracting security-related review sentences. It also accurately identifies misbehaviors, aspects and opinions from review sentences. A qualitative study shows that SRR-Miner outperforms two state-of-the-art approaches (AR-Miner and SUR-Miner) in terms of summarizing security issues and users’ sentiments. A further user survey indicates the usefulness of the summarization of SRR-Miner.
Conclusion
SRR-Miner is capable of automatically extracting security-related review sentences based on keywords, and summarizing misbehaviors, aspects and opinions of review sentences with a deep analysis of the sentence structures.},
  doi           = {https://doi.org/10.1016/j.infsof.2020.106290},
  issn          = {0950-5849},
  keywords      = {Mobile app review summarization, Natural language processing, Security and privacy},
  url           = {https://www.sciencedirect.com/science/article/pii/S0950584920300409},
}

@Article{KALAICHELAVAN2020547,
  author        = {Kanimozhi Kalaichelavan and Haroon Malik and Narman Husnu and Sreehari Sreenath},
  title         = {What Do People Complain About Drone Apps? A Large-Scale Empirical Study of Google Play Store Reviews},
  journal       = {Procedia Computer Science},
  year          = {2020},
  volume        = {170},
  pages         = {547-554},
  note          = {The 11th International Conference on Ambient Systems, Networks and Technologies (ANT) / The 3rd International Conference on Emerging Data and Industry 4.0 (EDI40) / Affiliated Workshops},
  __markedentry = {[jacekdabrowski:2]},
  abstract      = {Within the past few years, there has been a tremendous increase in the number of UAVs (Unmanned Aerial Vehicle) or drones manufacture and purchase. It is expected to proliferate further, penetrating into every stream of life, thus making its usage inevitable. The UAV’s major components are its physical hardware and programming software, which controls its navigation or performs various tasks based on the field of concern. The drone manufacturers launch the controlling app for the drones in mobile app stores. Few drone manufacturers also release development kits to aid drone enthusiasts in developing customized or more creative apps. Thus, the app stores are also expected to be flooded with drone-related apps in the near future. With various active researches and studies being carried out in UAV’s hardware field, no effort is dedicated to studying/researching the software side of UAV. Towards this end, a large-scale empirical study of UAV or drone-related apps of Google Play Store Platform is conducted. The study consisted of 1,825 UAV mobile apps, across twenty-five categories, with 162,250 reviews. Some of the notable findings of the study are (a) There are 27 major types the drone app users complain about. (b) The top four complains observed are Functional Error (27.9%), Device Compatibility (16.8%), Cost (16.2%) and Connection/Sync (15.6%). (c) The top four issues for which the UAV manufacturers or Drone app developers provide feedback to user complaints are Functional Error (40.9%), Cost (33.3%), Cost (16.2%), and Device Compatibility (23.1%). (d) Developers respond to the most frequently occurring complaints rather than the most negatively impacting ones.},
  doi           = {https://doi.org/10.1016/j.procs.2020.03.124},
  issn          = {1877-0509},
  keywords      = {UAV, Google Play Store, Mobiel Apps},
  url           = {https://www.sciencedirect.com/science/article/pii/S1877050920305627},
}

@Article{https://doi.org/10.1002/smr.2257,
  author        = {Gao, Shanquan and Liu, Lei and Liu, Yuzhou and Liu, Huaxiao and Wang, Yihui},
  title         = {Updating the goal model with user reviews for the evolution of an app},
  journal       = {Journal of Software: Evolution and Process},
  year          = {2020},
  volume        = {32},
  number        = {8},
  pages         = {e2257},
  note          = {e2257 JSME-19-0105.R2},
  __markedentry = {[jacekdabrowski:2]},
  abstract      = {Abstract Goal model is an important model in requirements engineering, and it can describe features and their relationships for supporting the development of apps. Since an app evolves continually, the goal model also needs to be updated with new requirements to guide the whole process. As the feedback of users, reviews provide an abundant resource of user requirements for updating the goal model. In this paper, we propose an approach to help developers (a) analyze reviews to gain the information of user requirements by training a classifier and defining keyword-based linguistic rules as well as grammar-based rules and (b) update the goal model with the extracted information, including improving existing goals and extending the model with new goals. In addition, we design a framework to represent results so that they can be understood by developers easily. According to our experiments based on the data in Google Play, the F-measure of classifier on reviews can reach 75.76\%, and the average precision for extracting requirements-related information from reviews is 84.04\%, then we can map the information to goals with the F-measure of 70.21\%. Furthermore, the survey on 22 developers shows that the information provided by us is useful for updating the goal model.},
  doi           = {https://doi.org/10.1002/smr.2257},
  eprint        = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/smr.2257},
  keywords      = {app evolution, goal model, review mining},
  url           = {https://onlinelibrary.wiley.com/doi/abs/10.1002/smr.2257},
}

@InProceedings{DBLP:conf/caise/0001LPS20,
  author        = {Jacek Dąbrowski and Emmanuel Letier and Anna Perini and Angelo Susi},
  title         = {Mining User Opinions to Support Requirement Engineering: An Empirical Study},
  booktitle     = {Advanced Information Systems Engineering - 32nd International Conference, CAiSE 2020, Grenoble, France, June 8-12, 2020, Proceedings},
  year          = {2020},
  editor        = {Schahram Dustdar and Eric Yu and Camille Salinesi and Dominique Rieu and Vik Pant},
  volume        = {12127},
  series        = {Lecture Notes in Computer Science},
  pages         = {401--416},
  publisher     = {Springer},
  __markedentry = {[jacekdabrowski:2]},
  bibsource     = {dblp computer science bibliography, https://dblp.org},
  biburl        = {https://dblp.org/rec/conf/caise/0001LPS20.bib},
  doi           = {10.1007/978-3-030-49435-3\_25},
  timestamp     = {Mon, 15 Jun 2020 17:06:51 +0200},
  url           = {https://doi.org/10.1007/978-3-030-49435-3\_25},
}

@InProceedings{DBLP:conf/quatic/MalgaonkarLS20,
  author        = {Saurabh Malgaonkar and Sherlock A. Licorish and Bastin Tony Roy Savarimuthu},
  title         = {Towards Automated Taxonomy Generation for Grouping App Reviews: {A} Preliminary Empirical Study},
  booktitle     = {Quality of Information and Communications Technology - 13th International Conference, {QUATIC} 2020, Faro, Portugal, September 9-11, 2020, Proceedings},
  year          = {2020},
  editor        = {Martin J. Shepperd and Fernando Brito e Abreu and Alberto Rodrigues da Silva and Ricardo P{\'{e}}rez{-}Castillo},
  volume        = {1266},
  series        = {Communications in Computer and Information Science},
  pages         = {120--134},
  publisher     = {Springer},
  __markedentry = {[jacekdabrowski:2]},
  bibsource     = {dblp computer science bibliography, https://dblp.org},
  biburl        = {https://dblp.org/rec/conf/quatic/MalgaonkarLS20.bib},
  doi           = {10.1007/978-3-030-58793-2\_10},
  timestamp     = {Tue, 15 Sep 2020 17:20:05 +0200},
  url           = {https://doi.org/10.1007/978-3-030-58793-2\_10},
}

@InProceedings{DBLP:conf/icsoc/XiaoCHW0X20,
  author        = {Jianmao Xiao and Shizhan Chen and Qiang He and Hongyue Wu and Zhiyong Feng and Xiao Xue},
  title         = {Detecting User Significant Intention via Sentiment-Preference Correlation Analysis for Continuous App Improvement},
  booktitle     = {Service-Oriented Computing - 18th International Conference, {ICSOC} 2020, Dubai, United Arab Emirates, December 14-17, 2020, Proceedings},
  year          = {2020},
  editor        = {Eleanna Kafeza and Boualem Benatallah and Fabio Martinelli and Hakim Hacid and Athman Bouguettaya and Hamid Motahari},
  volume        = {12571},
  series        = {Lecture Notes in Computer Science},
  pages         = {386--400},
  publisher     = {Springer},
  __markedentry = {[jacekdabrowski:2]},
  bibsource     = {dblp computer science bibliography, https://dblp.org},
  biburl        = {https://dblp.org/rec/conf/icsoc/XiaoCHW0X20.bib},
  doi           = {10.1007/978-3-030-65310-1\_27},
  timestamp     = {Wed, 16 Dec 2020 11:19:25 +0100},
  url           = {https://doi.org/10.1007/978-3-030-65310-1\_27},
}

@Article{Al-Hawari2020,
  author        = {Al-Hawari, Assem and Najadat, Hassan and Shatnawi, Raed},
  title         = {Classification of application reviews into software maintenance tasks using data mining techniques},
  journal       = {Software Quality Journal},
  year          = {2020},
  month         = {Aug},
  __markedentry = {[jacekdabrowski:2]},
  abstract      = {Mobile application reviews are considered a rich source of information for software engineers to provide a general understanding of user requirements and technical feedback to avoid main programming issues. Previous researches have used traditional data mining techniques to classify user reviews into several software maintenance tasks. In this paper, we aim to use associative classification (AC) algorithms to investigate the performance of different classifiers to classify reviews into several software maintenance tasks. Also, we proposed a new AC approach for review mining (ACRM). Review classification needs preprocessing steps to apply natural language preprocessing and text analysis. Also, we studied the influence of two feature selection techniques (information gain and chi-square) on classifiers. Association rules give a better understanding of users' intent since they discover the hidden patterns in words and features that are related to one of the maintenance tasks, and present it as class association rules (CARs). For testing the classifiers, we used two datasets that classify reviews into four different maintenance tasks. Results show that the highest accuracy was achieved by AC algorithms for both datasets. ACRM has the highest precision, recall, F-score, and accuracy. Feature selection helps improving the classifiers' performance significantly.},
  day           = {28},
  doi           = {10.1007/s11219-020-09529-8},
  issn          = {1573-1367},
  url           = {https://doi.org/10.1007/s11219-020-09529-8},
}

@Article{DBLP:journals/ase/WilliamsTEM20,
  author        = {Grant Williams and Miroslav Tushev and Fahimeh Ebrahimi and Anas Mahmoud},
  title         = {Modeling user concerns in Sharing Economy: the case of food delivery apps},
  journal       = {Autom. Softw. Eng.},
  year          = {2020},
  volume        = {27},
  number        = {3},
  pages         = {229--263},
  __markedentry = {[jacekdabrowski:2]},
  bibsource     = {dblp computer science bibliography, https://dblp.org},
  biburl        = {https://dblp.org/rec/journals/ase/WilliamsTEM20.bib},
  doi           = {10.1007/s10515-020-00274-7},
  timestamp     = {Fri, 06 Nov 2020 10:06:38 +0100},
  url           = {https://doi.org/10.1007/s10515-020-00274-7},
}

@InProceedings{DBLP:conf/hci/WenC20,
  author        = {Peihan Wen and Mo Chen},
  title         = {A New Analysis Method for User Reviews of Mobile Fitness Apps},
  booktitle     = {Human-Computer Interaction. Human Values and Quality of Life - Thematic Area, {HCI} 2020, Held as Part of the 22nd International Conference, {HCII} 2020, Copenhagen, Denmark, July 19-24, 2020, Proceedings, Part {III}},
  year          = {2020},
  editor        = {Masaaki Kurosu},
  volume        = {12183},
  series        = {Lecture Notes in Computer Science},
  pages         = {188--199},
  publisher     = {Springer},
  __markedentry = {[jacekdabrowski:2]},
  bibsource     = {dblp computer science bibliography, https://dblp.org},
  biburl        = {https://dblp.org/rec/conf/hci/WenC20.bib},
  doi           = {10.1007/978-3-030-49065-2\_14},
  timestamp     = {Mon, 13 Jul 2020 10:37:03 +0200},
  url           = {https://doi.org/10.1007/978-3-030-49065-2\_14},
}

@InProceedings{DBLP:conf/refsq/VlietGDB20,
  author        = {Martijn van Vliet and Eduard C. Groen and Fabiano Dalpiaz and Sjaak Brinkkemper},
  title         = {Identifying and Classifying User Requirements in Online Feedback via Crowdsourcing},
  booktitle     = {Requirements Engineering: Foundation for Software Quality - 26th International Working Conference, {REFSQ} 2020, Pisa, Italy, March 24-27, 2020, Proceedings {[REFSQ} 2020 was postponed]},
  year          = {2020},
  editor        = {Nazim H. Madhavji and Liliana Pasquale and Alessio Ferrari and Stefania Gnesi},
  volume        = {12045},
  series        = {Lecture Notes in Computer Science},
  pages         = {143--159},
  publisher     = {Springer},
  __markedentry = {[jacekdabrowski:2]},
  bibsource     = {dblp computer science bibliography, https://dblp.org},
  biburl        = {https://dblp.org/rec/conf/refsq/VlietGDB20.bib},
  doi           = {10.1007/978-3-030-44429-7\_11},
  timestamp     = {Wed, 10 Jun 2020 08:46:34 +0200},
  url           = {https://doi.org/10.1007/978-3-030-44429-7\_11},
}

@InProceedings{DBLP:conf/hci/SharmaB20,
  author        = {Tanusree Sharma and Masooda N. Bashir},
  title         = {Privacy Apps for Smartphones: An Assessment of Users' Preferences and Limitations},
  booktitle     = {{HCI} for Cybersecurity, Privacy and Trust - Second International Conference, {HCI-CPT} 2020, Held as Part of the 22nd {HCI} International Conference, {HCII} 2020, Copenhagen, Denmark, July 19-24, 2020, Proceedings},
  year          = {2020},
  editor        = {Abbas Moallem},
  volume        = {12210},
  series        = {Lecture Notes in Computer Science},
  pages         = {533--546},
  publisher     = {Springer},
  __markedentry = {[jacekdabrowski:2]},
  bibsource     = {dblp computer science bibliography, https://dblp.org},
  biburl        = {https://dblp.org/rec/conf/hci/SharmaB20.bib},
  doi           = {10.1007/978-3-030-50309-3\_35},
  timestamp     = {Tue, 27 Apr 2021 15:13:52 +0200},
  url           = {https://doi.org/10.1007/978-3-030-50309-3\_35},
}

@InProceedings{DBLP:conf/re/TizardRB20,
  author        = {James Tizard and Tim Rietz and Kelly Blincoe},
  title         = {Voice of the Users: A Demographic Study of Software Feedback Behaviour},
  booktitle     = {28th {IEEE} International Requirements Engineering Conference, {RE} 2020, Zurich, Switzerland, August 31 - September 4, 2020},
  year          = {2020},
  editor        = {Travis D. Breaux and Andrea Zisman and Samuel Fricker and Martin Glinz},
  pages         = {55--65},
  publisher     = {{IEEE}},
  __markedentry = {[jacekdabrowski:2]},
  bibsource     = {dblp computer science bibliography, https://dblp.org},
  biburl        = {https://dblp.org/rec/conf/re/TizardRB20.bib},
  doi           = {10.1109/RE48521.2020.00018},
  timestamp     = {Fri, 09 Apr 2021 18:48:05 +0200},
  url           = {https://doi.org/10.1109/RE48521.2020.00018},
}

@InProceedings{DBLP:conf/re/OehriG20,
  author        = {Emanuel Oehri and Emitza Guzman},
  title         = {Same Same but Different: Finding Similar User Feedback Across Multiple Platforms and Languages},
  booktitle     = {28th {IEEE} International Requirements Engineering Conference, {RE} 2020, Zurich, Switzerland, August 31 - September 4, 2020},
  year          = {2020},
  editor        = {Travis D. Breaux and Andrea Zisman and Samuel Fricker and Martin Glinz},
  pages         = {44--54},
  publisher     = {{IEEE}},
  __markedentry = {[jacekdabrowski:2]},
  bibsource     = {dblp computer science bibliography, https://dblp.org},
  biburl        = {https://dblp.org/rec/conf/re/OehriG20.bib},
  doi           = {10.1109/RE48521.2020.00017},
  timestamp     = {Wed, 14 Oct 2020 14:28:47 +0200},
  url           = {https://doi.org/10.1109/RE48521.2020.00017},
}

@InProceedings{DBLP:conf/wcre/YadavSF20,
  author        = {Aman Yadav and Rishab Sharma and Fatemeh Hendijani Fard},
  title         = {A Semantic-Based Framework for Analyzing App Users' Feedback},
  booktitle     = {27th {IEEE} International Conference on Software Analysis, Evolution and Reengineering, {SANER} 2020, London, ON, Canada, February 18-21, 2020},
  year          = {2020},
  editor        = {Kostas Kontogiannis and Foutse Khomh and Alexander Chatzigeorgiou and Marios{-}Eleftherios Fokaefs and Minghui Zhou},
  pages         = {572--576},
  publisher     = {{IEEE}},
  __markedentry = {[jacekdabrowski:2]},
  bibsource     = {dblp computer science bibliography, https://dblp.org},
  biburl        = {https://dblp.org/rec/conf/wcre/YadavSF20.bib},
  doi           = {10.1109/SANER48275.2020.9054843},
  timestamp     = {Thu, 16 Apr 2020 16:52:52 +0200},
  url           = {https://doi.org/10.1109/SANER48275.2020.9054843},
}

@InProceedings{DBLP:conf/IEEEscc/UddinHHC20,
  author        = {M. D. Kafil Uddin and Qiang He and Jun Han and Caslon Chua},
  title         = {App Competition Matters: How to Identify Your Competitor Apps?},
  booktitle     = {2020 {IEEE} International Conference on Services Computing, {SCC} 2020, Beijing, China, November 7-11, 2020},
  year          = {2020},
  pages         = {370--377},
  publisher     = {{IEEE}},
  __markedentry = {[jacekdabrowski:2]},
  bibsource     = {dblp computer science bibliography, https://dblp.org},
  biburl        = {https://dblp.org/rec/conf/IEEEscc/UddinHHC20.bib},
  doi           = {10.1109/SCC49832.2020.00055},
  timestamp     = {Mon, 21 Dec 2020 10:51:09 +0100},
  url           = {https://doi.org/10.1109/SCC49832.2020.00055},
}

@InProceedings{DBLP:conf/bdc/KunaefiA20,
  author        = {Anang Kunaefi and Masayoshi Aritsugi},
  title         = {Characterizing User Decision based on Argumentative Reviews},
  booktitle     = {7th {IEEE/ACM} International Conference on Big Data Computing, Applications and Technologies, {BDCAT} 2020, Leicester, United Kingdom, December 7-10, 2020},
  year          = {2020},
  pages         = {161--170},
  publisher     = {{IEEE}},
  __markedentry = {[jacekdabrowski:2]},
  bibsource     = {dblp computer science bibliography, https://dblp.org},
  biburl        = {https://dblp.org/rec/conf/bdc/KunaefiA20.bib},
  doi           = {10.1109/BDCAT50828.2020.00002},
  timestamp     = {Wed, 19 May 2021 08:31:45 +0200},
  url           = {https://doi.org/10.1109/BDCAT50828.2020.00002},
}

@Article{DBLP:journals/iet-sen/LiuLLG20,
  author        = {Yuzhou Liu and Lei Liu and Huaxiao Liu and Shanquan Gao},
  title         = {Combining goal model with reviews for supporting the evolution of apps},
  journal       = {{IET} Softw.},
  year          = {2020},
  volume        = {14},
  number        = {1},
  pages         = {39--49},
  __markedentry = {[jacekdabrowski:2]},
  bibsource     = {dblp computer science bibliography, https://dblp.org},
  biburl        = {https://dblp.org/rec/journals/iet-sen/LiuLLG20.bib},
  doi           = {10.1049/iet-sen.2018.5192},
  timestamp     = {Tue, 14 Jul 2020 16:09:24 +0200},
  url           = {https://doi.org/10.1049/iet-sen.2018.5192},
}

@Article{https://doi.org/10.1002/smr.2316,
  author        = {Di Sorbo, Andrea and Grano, Giovanni and Aaron Visaggio, Corrado and Panichella, Sebastiano},
  title         = {Investigating the criticality of user-reported issues through their relations with app rating},
  journal       = {Journal of Software: Evolution and Process},
  year          = {2020},
  volume        = {33},
  number        = {3},
  pages         = {e2316},
  note          = {e2316 smr.2316},
  __markedentry = {[jacekdabrowski:2]},
  abstract      = {Abstract App quality impacts user experience and satisfaction. As a consequence, both app ratings and user feedback reported in app reviews are directly influenced by the user-perceived app quality. Through an empirical study involving 210,517 reviews related to 317 Android apps, in this paper, we experiment with the combined usage of app rating and user reviews analysis (i) to investigate the most important factors influencing the perceived app quality, (ii) focusing on the topics discussed in user review that most relate with app rating. Besides, we investigate whether specific code quality metrics could be monitored to prevent the rising of negative user feedback (i.e., types of user review comments), connected with low ratings. Our study demonstrates that user comments reporting bugs are negatively correlated with the rating, while reviews reportingfeature requests do not. Interestingly, depending on the app category, we observed that different kinds of issues have rather different relationships with the rating and the user-perceived quality of the app. In particular, we observe that for specific app categories (e.g., communication), some code quality factors have significant relationships with the raising of certain types of feedback, which, in turn, are negatively connected with app ratings.},
  doi           = {https://doi.org/10.1002/smr.2316},
  eprint        = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/smr.2316},
  keywords      = {app reviews, mobile apps, software maintenance and evolution, software quality},
  url           = {https://onlinelibrary.wiley.com/doi/abs/10.1002/smr.2316},
}

@Comment{jabref-meta: databaseType:bibtex;}
