Reference, Description, Size, Access, Primary Study
Chen et al. (2014), Indicated whether the content of each review is informative or uninformative., "12,000", Upon Request, "Chen et al., ""AR-Miner: Mining Informative Reviews for Developers from Mobile App Marketplace"", ICSE, 2014"
Guzman et al. (2015), "Tagged reviews with topics (e.g., bug report, feature shortcoming, complaint, usage scenario).", "4,500", Upon Request, "Guzman et al., ""Ensemble Methods for App Review Classification: An Approach for Software Evolution"", ASE, 2015"
Gu and Kim (2015), "Identified type of user request each review convey (e.g., bug report, feature requests).", "2,000", Upon Request, "Gu and Kim, ""What Parts of Your Apps are Loved by Users?"", ASE, 2015"
Maalej and Nabil (2015), "Reviews labeled with a type of user requests (bug report, feature request, rating, user experience).", "4,400", Upon Request, "Maalej and Nabil, ""Bug report, feature request, or simply praise? On automatically classifying app reviews"", RE, 2015"
Di Sorbo et al. (2016), "Reviews labeled with 12 topics (e.g. security) and user intention (e.g., problem discovery).", "3,439", https://spanichella.github.io/tools.html, "Di Sorbo et al., ""What Would Users Change in My App? Summarizing App Reviews for Recommending Software Changes"", FSE, 2016"
Panichella et al. (2016), "Reviews labeled with 5 categories useful from maintenance perspective (e.g., problem discovery).", 852, https://spanichella.github.io/tools.html, "Panichella et al.,""ARdoc: App Reviews Development Oriented Classifier"", FSE, 2016"
Sänger et al. (2016), "Identified user opinions (feature and sentiment).", "1,760", Upon Request, "Sänger et al., ""SCARE - The Sentiment Corpus of App Reviews with Fine-grained Annotations in German"", LREC, 2016"
Ciurumelea et al. (2017), "Tagged reviews with mobile specific categories (e.g. performance, resources, battery, memory).", "1,566", https://zenodo.org/record/161842#.YNn7cS0Rp69, "Ciurumelea et al., ""Analyzing reviews and code of mobile apps for better release planning"", SANER, 2017"
Groen et al. (2017), "Labeled reviews with software quality requirements (e.g., usability, reliability, portability, compatibility).", 360, Upon Request, "Groen et al., ""Users — The Hidden Software Product Quality Experts?: A Study on How App Users Report Quality Aspects in Online Reviews"", RE, 2017"
Lu and Liang (2017), "Reviews labeled with functional and non-functional requirements (e.g., us- ability, performance).", "2,000", https://www.dropbox.com/sh/05mteyyo7uj4w0n/AAAgKbottac7YchpH3qidPUXa?dl=0, "Lu and Liang, ""Automatic Classification of Non-Functional Requirements from Augmented App User Reviews"", EASE, 2017"
Grano et al. (2018), "Annotated reviews with their topics and a type of issue users reports.", "6,600", https://spanichella.github.io/tools.html, "Grano et al., ""Exploring the integration of user feedback in automated testing of Android applications"", SANER, 2018"
Jha and Mahmoud (2018), "Annotated a type of user feedback (feature request, bug reports, and others).", "2,930", http://seel.cse.lsu.edu/data/emse18.zip, "Jha and Mahmoud, ""Using frame semantics for classifying and summarizing application store reviews"", EMSE, 2018"
Nayebi et al. (2018), "Annotated reviews with a type of a user request (e.g., problem discovery).", "2,383",  https://github.com/MaQuest/AIRE2018_Feedback-from-Tweets-vs-App-Store, "Nayebi et al., ""App store mining is not enough for app improvement"", EMSE, 2018"
Pelloni et al. (2018), "Reviews labeled with a crash report category.", 534, https://github.com/sealuzh/saner18/blob/master/rq1/LLT.csv, "Pelloni et al., ""BECLoMA: Augmenting stack traces with user review information"", SANER, 2018"
Scoccia et al. (2018), "Annotated reviews with 10 categories of recurring users’s concern.", "1,000", https://mega.nz/file/5sVzCRwD#ad-PFyU72JCL8AkcCGi_45w-z60CYa0EEjWqAWGiljQ, "Scoccia et al., ""An Investigation into Android Run-Time Permissions from the End Users’ Perspective"", MOBILESoft, 2018"

Al Kilani et al. (2019), x, x, Upon Request, x" 

Dąbrowski et al. (2019), "Reviews annotated with 20 app features.", 200, Upon Request, "Dąbrowski et al., ""Finding and Analyzing App Reviews Related to Specific Features: A Research Preview"", REFSQ, 2019"
Jha and Mahmoud (2019), "Labeled reviews with non-functional requirements user discuss (e.g. usability, dependability).", "6,000", http://seel.cse.lsu.edu/data/emse19.zip, "Jha and Mahmoud, ""Mining non-functional requirements from App store reviews"", EMSE, 2019"
Scalabrino et al. (2019), "Reviews labeled with feedback category (e.g., bug report, feature request).", "3,000", https://dibt.unimol.it/reports/clap/downloads/rq1-raw-data.csv, "Scalabrino et al. , ""Listening to the Crowd for the Release Planning of Mobile Apps"", TSE, 2019"
Shah et al. (2019a), "Identified features discussed in reviews.", "3,500", https://bitbucket.org/faizalishah/, "Shah et al., ""Simulating the Impact of Annotation Guidelines and Annotated Data on Extracting App Features from App Reviews"", ICSOFT, 2019"
Stanik et al. (2019), "Annotated a type of user feedback (problem reports, inquiries, and irrelevant).", "6,406", https://mast.informatik.uni-hamburg.de/replication-packages/, "Stanik et al., ""Classifying Multilingual User Feedback using Traditional Machine Learning and Deep Learning"", REW, 2019"
